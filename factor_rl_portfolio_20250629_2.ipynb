{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhjung74/paper/blob/main/factor_rl_portfolio_20250629_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjVbbjLLAF8r",
        "outputId": "a03353ad-c5ce-4eee-a76f-89f570131a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "colab......\n",
            "g_drive= True\n"
          ]
        }
      ],
      "source": [
        "# ë”¥ëŸ¬ë‹ ì²˜ë¦¬ í™˜ê²½ requirements\n",
        "g_drive = False\n",
        "mac_gpu = False\n",
        "# colab\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "# print(IN_COLAB)\n",
        "\n",
        "if IN_COLAB:\n",
        "    print('colab......')\n",
        "    g_drive = True\n",
        "    # google drive setting\n",
        "    #from google.colab import drive\n",
        "    #drive.mount('/content/drive')\n",
        "    #import os\n",
        "    #try:\n",
        "    #    import transformers, emoji, soynlp, pytorch_lightning\n",
        "    #except:\n",
        "    #    ! pip install -U -q transformers emoji soynlp pytorch-lightning snoop wandb sklearn seaborn pandas numpy\n",
        "    # restart runtime\n",
        "    #os.kill(os.getpid(), 9)\n",
        "elif IN_COLAB==False:\n",
        "    print('not colab')\n",
        "    g_drive = False\n",
        "    #import os\n",
        "    #try:\n",
        "    #    import transformers, emoji, soynlp, pytorch_lightning\n",
        "    #except:\n",
        "    #    ! pip install -U -q transformers emoji soynlp pytorch-lightning snoop wandb sklearn seaborn pandas numpy\n",
        "    #    ! pip install -q torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "\n",
        "print('g_drive=',g_drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jt7QMSmQALOD",
        "outputId": "48a64e23-2897-4d21-9d51-4ccd9c385e01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Linux'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import platform\n",
        "\n",
        "platform.system()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EtSEJo3EANjC"
      },
      "outputs": [],
      "source": [
        "os_type = platform.system()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7esZJ8wAQFQ",
        "outputId": "2d460155-cec9-4d50-af75-21c33780afb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mac_gpu= False\n"
          ]
        }
      ],
      "source": [
        "# Os ì¢…ë¥˜ë¥¼ í™•ì¸í•œë‹¤.\n",
        "if os_type == 'Darwin':\n",
        "    mac_gpu = True\n",
        "else:\n",
        "    mac_gpu = False\n",
        "print('mac_gpu=',mac_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzUTNK2sASRg",
        "outputId": "66931696-3d94-431a-d2fb-cb523348bd27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n"
          ]
        }
      ],
      "source": [
        "if g_drive == True:\n",
        "  !pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if g_drive == True:\n",
        "  !pip install PyPortfolioOpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790d2aad-6419-4a89-e6e0-6b2a161776d9",
        "id": "1QQuVHJ4YY94"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPortfolioOpt in /usr/local/lib/python3.11/dist-packages (1.5.6)\n",
            "Requirement already satisfied: cvxpy>=1.1.19 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (1.6.6)\n",
            "Requirement already satisfied: ecos<3.0.0,>=2.0.14 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (2.0.14)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (2.2.2)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (5.24.1)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (1.15.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (24.2)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (1.0.4)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (0.11.1)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (3.2.7.post2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.11/dist-packages (from clarabel>=0.5.0->cvxpy>=1.1.19->PyPortfolioOpt) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (75.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->PyPortfolioOpt) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi->clarabel>=0.5.0->cvxpy>=1.1.19->PyPortfolioOpt) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if g_drive == True:\n",
        "  !pip install shimmy>=0.2.1"
      ],
      "metadata": {
        "id": "37UgNTd56-ev"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if g_drive == True:\n",
        "  !pip install stable-baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9422c7e4-e074-4fc6-9ff2-20a7e436bad6",
        "id": "HfgOeFUJ6-ex"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-zL0l1Rtz_3T"
      },
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "if g_drive==False:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    base_dir = '/content/gdrive/My Drive/Colab Notebooks/aSSIST/factor_Project'\n",
        "    data_dir = os.path.join(base_dir, 'data')\n",
        "\n",
        "    # ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    # ê²½ë¡œ ì´ë™\n",
        "    os.chdir(data_dir)\n",
        "\n",
        "    # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "    MODEL_DIR = data_dir  # ë˜ëŠ” MODEL_DIR = os.getcwd()\n",
        "\n",
        "    # ê²½ë¡œ í™•ì¸\n",
        "    print(f\"í˜„ì¬ ì‘ì—… ê²½ë¡œ: {os.getcwd()}\")\n",
        "    print(f\"ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {MODEL_DIR}\")"
      ],
      "metadata": {
        "id": "ACI-jNmSi8KR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l3Crew5Zz39x"
      },
      "outputs": [],
      "source": [
        "start_date ='2019-01-01'\n",
        "end_date ='2025-06-30'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYBiTktKAtEo",
        "outputId": "0167e603-4210-41df-a1e9-79ac40df1276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'=0.2.1'   df_factors.xlsx   df_price.xlsx   df_returns.xlsx   sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noPxJw4VArMg",
        "outputId": "9de9c443-c0ea-4c17-a54e-22d638e64a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì²« ë²ˆì§¸ ì‹¤í—˜ (PPO + Crypto + Sharpe ë³´ìƒ)"
      ],
      "metadata": {
        "id": "U8aw7Xfnb8UB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë‹¤ìŒ 6ê°€ì§€ ì‹¤í—˜ì„ í•œ ë²ˆì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµ\n",
        "\n",
        "Crypto_PPO_sharpe\n",
        "\n",
        "Crypto_PPO_beta\n",
        "\n",
        "Crypto_SAC_sharpe\n",
        "\n",
        "Crypto_SAC_beta\n",
        "\n",
        "Crypto_TD3_sharpe\n",
        "\n",
        "Crypto_TD3_beta"
      ],
      "metadata": {
        "id": "4eyFZFQdfqxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ìµœì¢…ì†ŒìŠ¤ 20250616"
      ],
      "metadata": {
        "id": "CwQdLK-LzBGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import shap\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from gym import spaces\n",
        "from stable_baselines3 import PPO, SAC, TD3\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import torch\n",
        "import random\n",
        "from sklearn.linear_model import LinearRegression  # ì¶”ê°€\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from scipy.stats import ttest_ind, mannwhitneyu\n",
        "\n",
        "from pypfopt import expected_returns, risk_models\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Seed ì„¤ì •\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "show_summary = True\n",
        "\n",
        "# ìì‚°êµ° ì„¤ì •\n",
        "# ğŸ“ ë¯¸êµ­ ê°œë³„ì£¼ (Big Tech + S&P/Dow ì¢…ëª© ì¤‘ ëŒ€í‘œ)\n",
        "stock_assets = [\n",
        "    \"AAPL\",  # Apple\n",
        "    \"MSFT\",  # Microsoft\n",
        "    \"GOOGL\", # Alphabet (Google)\n",
        "    \"AMZN\",  # Amazon\n",
        "    \"META\",  # Meta (Facebook)\n",
        "    \"TSLA\",  # Tesla\n",
        "    \"NVDA\",  # Nvidia\n",
        "    \"NFLX\",  # Netflix\n",
        "    \"JPM\",   # JPMorgan Chase\n",
        "    \"V\",     # Visa\n",
        "    \"DIS\",   # Disney\n",
        "    \"INTC\",  # Intel\n",
        "    \"BA\",    # Boeing\n",
        "    \"XOM\",   # Exxon Mobil\n",
        "    \"JNJ\",   # Johnson & Johnson\n",
        "    \"KO\",    # Coca-Cola\n",
        "    \"PG\",    # Procter & Gamble\n",
        "    \"WMT\",   # Walmart\n",
        "    \"UNH\",   # UnitedHealth Group\n",
        "]\n",
        "\n",
        "# ğŸ“ ETF (ëŒ€í‘œì§€ìˆ˜ ETF)\n",
        "etf_assets = [\n",
        "    \"SPY\",  # S&P 500 ETF\n",
        "    \"QQQ\",  # NASDAQ 100 ETF\n",
        "    \"DIA\",  # Dow Jones ETF\n",
        "]\n",
        "\n",
        "# ğŸ“ í•´ì™¸ ì£¼ìš” ê°œë³„ì£¼ (ë¯¸êµ­ ì™¸ ìƒì¥ ì¢…ëª©)\n",
        "equity_assets = [\n",
        "    \"BABA\", # Alibaba (NYSE)\n",
        "    \"TSM\",  # Taiwan Semiconductor (NYSE/TSMC)\n",
        "]\n",
        "\n",
        "# ğŸ“ ì•”í˜¸í™”í (Crypto Currencies)\n",
        "crypto_assets = [\n",
        "    \"BTC-USD\",  # Bitcoin\n",
        "    \"ETH-USD\",  # Ethereum\n",
        "    \"BNB-USD\",  # Binance Coin\n",
        "    \"SOL-USD\",  # Solana\n",
        "]\n",
        "\n",
        "\n",
        "macro_assets = [\n",
        "    # ì±„ê¶Œ ë° ê¸ˆë¦¬ ê´€ë ¨\n",
        "    \"TLT\",     # iShares 20+ Year Treasury Bond ETF\n",
        "    \"IEF\",     # iShares 7-10 Year Treasury Bond ETF\n",
        "    \"^TNX\",    # CBOE 10-Year Treasury Yield Index (ë¯¸êµ­ 10ë…„ë¬¼ ìˆ˜ìµë¥ )\n",
        "    \"^IRX\",    # CBOE 13-week Treasury Bill Yield\n",
        "\n",
        "    # ì›ìì¬ ê´€ë ¨\n",
        "    \"GLD\",     # SPDR Gold Shares (ê¸ˆ)\n",
        "    \"SLV\",     # iShares Silver Trust (ì€)\n",
        "    \"USO\",     # United States Oil Fund (åŸæ²¹)\n",
        "    \"DBB\",     # Invesco DB Base Metals Fund (ê¸ˆì†)\n",
        "    \"DBC\",     # Invesco DB Commodity Index Tracking Fund (ì¢…í•© ì›ìì¬)\n",
        "\n",
        "    # ì¸í”Œë ˆì´ì…˜ ê´€ë ¨\n",
        "    \"TIP\",     # iShares TIPS Bond ETF (ë¬¼ê°€ì—°ë™ì±„)\n",
        "]\n",
        "\n",
        "\n",
        "# ğŸ“ ì „ì²´ í†µí•© ìì‚°êµ°\n",
        "#mixed_assets = stock_assets + etf_assets + equity_assets + crypto_assets + macro_assets\n",
        "mixed_assets = [\"AAPL\",\"MSFT\",\"TSLA\",\"SPY\",\"BTC-USD\",\"TLT\",\"GLD\"]\n",
        "#mixed_assets = stock_assets\n",
        "print(mixed_assets)\n",
        "\n",
        "def save_model(model, save_path=\"models\", filename=\"ppo_model.zip\"):\n",
        "    import os\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    model.save(os.path.join(save_path, filename))\n",
        "\n",
        "def load_model(model_class, env, save_path=\"models\", filename=\"ppo_model.zip\"):\n",
        "    from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "    return model_class.load(os.path.join(save_path, filename), env=env)\n",
        "\n",
        "\n",
        "def compare_strategies(series1, series2, label1=\"A\", label2=\"B\"):\n",
        "    \"\"\"\n",
        "    ë‘ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ì‹œê³„ì—´ì— ëŒ€í•´ t-testì™€ Mannâ€“Whitney U-test ìˆ˜í–‰\n",
        "    \"\"\"\n",
        "    returns1 = series1.pct_change().dropna()\n",
        "    returns2 = series2.pct_change().dropna()\n",
        "\n",
        "    # ê¸¸ì´ ë§ì¶”ê¸°\n",
        "    min_len = min(len(returns1), len(returns2))\n",
        "    returns1 = returns1[-min_len:]\n",
        "    returns2 = returns2[-min_len:]\n",
        "\n",
        "    # í‰ê· ì°¨ì´ ê²€ì • (t-test)\n",
        "    t_stat, t_p = ttest_ind(returns1, returns2, equal_var=False)\n",
        "\n",
        "    # ë¹„ëª¨ìˆ˜ ê²€ì • (Mannâ€“Whitney U-test)\n",
        "    u_stat, u_p = mannwhitneyu(returns1, returns2, alternative='two-sided')\n",
        "\n",
        "    print(f\"\\nğŸ” [{label1} vs {label2}]\")\n",
        "    print(f\"â–¶ t-test p-value: {t_p:.4f} â†’ {'ìœ ì˜ë¯¸í•¨' if t_p < 0.05 else 'ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ'}\")\n",
        "    print(f\"â–¶ Mannâ€“Whitney U-test p-value: {u_p:.4f} â†’ {'ìœ ì˜ë¯¸í•¨' if u_p < 0.05 else 'ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ'}\")\n",
        "\n",
        "    return {\n",
        "        \"t_p\": t_p,\n",
        "        \"u_p\": u_p\n",
        "    }\n",
        "\n",
        "\n",
        "# ì‹œê°„ê°€ë³€ ë² íƒ€ ê³„ì‚° í•¨ìˆ˜ (ì¶”ê°€)\n",
        "def compute_rolling_beta_old(price_data: pd.DataFrame, volume_data: pd.DataFrame, window: int = 60) -> pd.DataFrame:\n",
        "    #ê¸°ìˆ ì  ìš”ì¸(Momentum, Volatility, MA Deviation, Volume Z-score, Sharpe, MDD)ì„ ì´ìš©í•´\n",
        "    #ê° ìì‚°ë³„ 60ì¼ ë¡¤ë§ íšŒê·€ë¥¼ ìˆ˜í–‰í•˜ê³ , ì‹œê°„ê°€ë³€ì  ë² íƒ€ ê³„ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "    #Volatilityì™€ VolumeZëŠ” 'ë‚®ì„ìˆ˜ë¡ ì¢‹ë‹¤'ëŠ” ë°©í–¥ì„ ë³´ìƒì— ë§ê²Œ ë°˜ì˜.\n",
        "    #\"\"\"\n",
        "    log_return = np.log(price_data / price_data.shift(1))\n",
        "    momentum = price_data.pct_change(20)\n",
        "    volatility_raw = log_return.rolling(20).std()\n",
        "    volatility_score = 1 / (1 + volatility_raw)  # ë‚®ì„ìˆ˜ë¡ score â†‘\n",
        "\n",
        "    ma = price_data.rolling(20).mean()\n",
        "    ma_deviation = (price_data - ma) / ma\n",
        "\n",
        "    volume_z_raw = (volume_data - volume_data.rolling(20).mean()) / volume_data.rolling(20).std()\n",
        "    volume_z_score = 1 / (1 + volume_z_raw.abs())  # ì ˆëŒ“ê°’ ê¸°ì¤€, ë‚®ì„ìˆ˜ë¡ ì•ˆì •\n",
        "\n",
        "    beta_data = {}\n",
        "    for asset in price_data.columns:\n",
        "        asset_df = pd.DataFrame({\n",
        "            \"y\": log_return[asset],\n",
        "            \"momentum\": momentum[asset],\n",
        "            \"volatility\": volatility_score[asset],\n",
        "            \"ma_dev\": ma_deviation[asset],\n",
        "            \"volume_z\": volume_z_score[asset]\n",
        "        }).dropna()\n",
        "\n",
        "        betas = []\n",
        "        index_list = []\n",
        "        for i in range(window, len(asset_df)):\n",
        "            y = asset_df[\"y\"].iloc[i - window:i].values\n",
        "            X = asset_df[[\"momentum\", \"volatility\", \"ma_dev\", \"volume_z\"]].iloc[i - window:i].values\n",
        "            price_window = price_data[asset].iloc[i - window:i]\n",
        "            returns = price_window.pct_change().dropna()\n",
        "            if np.any(np.isnan(X)) or np.any(np.isnan(y)) or returns.empty:\n",
        "                betas.append([np.nan] * 6)\n",
        "                index_list.append(asset_df.index[i])\n",
        "                continue\n",
        "            reg = LinearRegression().fit(X, y)\n",
        "            sharpe = returns.mean() / (returns.std() + 1e-6)\n",
        "            cumulative = (1 + returns).cumprod()\n",
        "            peak = cumulative.cummax()\n",
        "            drawdown = (cumulative - peak) / peak\n",
        "            mdd = drawdown.min()\n",
        "            beta_mdd = 1 - abs(mdd)  # MDDëŠ” ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ\n",
        "            betas.append(list(reg.coef_) + [sharpe, beta_mdd])\n",
        "            index_list.append(asset_df.index[i])\n",
        "\n",
        "        beta_df = pd.DataFrame(betas, columns=[\"beta_mom\", \"beta_vol\", \"beta_ma\", \"beta_volz\", \"beta_sharpe\", \"beta_mdd\"], index=index_list)\n",
        "        beta_data[asset] = beta_df\n",
        "\n",
        "    beta_panel = pd.concat(beta_data, axis=1)\n",
        "    beta_panel.index.name = \"Date\"\n",
        "    return beta_panel\n",
        "\n",
        "def compute_rolling_beta(price_data: pd.DataFrame, volume_data: pd.DataFrame, window: int = 60) -> pd.DataFrame:\n",
        "    log_return = np.log(price_data / price_data.shift(1))\n",
        "    momentum = price_data.pct_change(20)\n",
        "    volatility_raw = log_return.rolling(20).std()\n",
        "    volatility_score = 1 / (1 + volatility_raw)\n",
        "\n",
        "    ma = price_data.rolling(20).mean()\n",
        "    ma_deviation = (price_data - ma) / ma\n",
        "\n",
        "    volume_z_raw = (volume_data - volume_data.rolling(20).mean()) / volume_data.rolling(20).std()\n",
        "    volume_z_score = 1 / (1 + volume_z_raw.abs())\n",
        "\n",
        "    beta_data = {}\n",
        "    asset_list = price_data.columns\n",
        "    n_assets = len(asset_list)\n",
        "\n",
        "    for asset in asset_list:\n",
        "        asset_df = pd.DataFrame({\n",
        "            \"y\": log_return[asset],\n",
        "            \"momentum\": momentum[asset],\n",
        "            \"volatility\": volatility_score[asset],\n",
        "            \"ma_dev\": ma_deviation[asset],\n",
        "            \"volume_z\": volume_z_score[asset]\n",
        "        }).dropna()\n",
        "\n",
        "        betas = []\n",
        "        index_list = []\n",
        "\n",
        "        for i in range(window, len(asset_df)):\n",
        "            y = asset_df[\"y\"].iloc[i - window:i].values\n",
        "            X = asset_df[[\"momentum\", \"volatility\", \"ma_dev\", \"volume_z\"]].iloc[i - window:i].values\n",
        "            price_window = price_data[asset].iloc[i - window:i]\n",
        "            returns = price_window.pct_change().dropna()\n",
        "\n",
        "            if np.any(np.isnan(X)) or np.any(np.isnan(y)) or returns.empty:\n",
        "                betas.append([np.nan] * 7)\n",
        "                index_list.append(asset_df.index[i])\n",
        "                continue\n",
        "\n",
        "            reg = LinearRegression().fit(X, y)\n",
        "            sharpe = returns.mean() / (returns.std() + 1e-6)\n",
        "            cumulative = (1 + returns).cumprod()\n",
        "            peak = cumulative.cummax()\n",
        "            drawdown = (cumulative - peak) / peak\n",
        "            mdd = drawdown.min()\n",
        "            beta_mdd = 1 - abs(mdd)\n",
        "\n",
        "            # âœ… EqualWeight ìœ ì‚¬ë„ (ê°€ê²© ê¸°ë°˜)\n",
        "            weights_price = price_data.iloc[i - 1] / price_data.iloc[i - 1].sum()\n",
        "            eqw = 1 / n_assets\n",
        "            eqw_similarity_price = 1 - abs(weights_price[asset] - eqw)  # 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ EWì— ìœ ì‚¬\n",
        "\n",
        "            # âœ… EqualWeight ìœ ì‚¬ë„ (ì •ì±… ê¸°ë°˜)\n",
        "            action_t = np.zeros(n_assets)\n",
        "            action_t[list(price_data.columns).index(asset)] = 1.0  # ë‹¨ì¼ ìì‚° íˆ¬ì ê°€ì •\n",
        "            weights_eqw = np.ones(n_assets) / n_assets\n",
        "            eqw_similarity_policy = 1 - np.linalg.norm(action_t - weights_eqw)\n",
        "\n",
        "            # âœ… íŒ©í„° ì €ì¥\n",
        "            betas.append(list(reg.coef_) + [sharpe, beta_mdd, eqw_similarity_price, eqw_similarity_policy])\n",
        "            index_list.append(asset_df.index[i])\n",
        "\n",
        "        beta_df = pd.DataFrame(\n",
        "            betas,\n",
        "            columns=[\n",
        "                \"beta_mom\", \"beta_vol\", \"beta_ma\", \"beta_volz\",\n",
        "                \"beta_sharpe\", \"beta_mdd\",\n",
        "                \"beta_eqw_price\", \"beta_eqw_policy\"\n",
        "            ],\n",
        "            index=index_list\n",
        "        )\n",
        "        beta_data[asset] = beta_df\n",
        "\n",
        "    beta_panel = pd.concat(beta_data, axis=1)\n",
        "    beta_panel.index.name = \"Date\"\n",
        "    return beta_panel\n",
        "\n",
        "\n",
        "# ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ìˆ˜ì •: ê±°ë˜ëŸ‰ ë°ì´í„° ì¶”ê°€ ë° ë² íƒ€ í†µí•©)\n",
        "def fetch_data(assets, start=start_date, end=end_date):\n",
        "    # ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ì¢…ê°€ + ê±°ë˜ëŸ‰)\n",
        "    data = yf.download(assets, start=start, end=end, auto_adjust=True, progress=False, threads=False)\n",
        "    price = data[\"Close\"].ffill().bfill().dropna()\n",
        "    volume = data[\"Volume\"].ffill().bfill().dropna()\n",
        "\n",
        "    # ê¸°ì¡´ íŒ©í„° ê³„ì‚°\n",
        "    returns = price.pct_change().dropna()\n",
        "    momentum = price.pct_change(20).dropna()\n",
        "    volatility = returns.rolling(20).std().dropna()\n",
        "    factors = pd.concat([momentum.add_suffix(\"_mom\"), volatility.add_suffix(\"_vol\")], axis=1).dropna()\n",
        "\n",
        "    # ì‹œê°„ê°€ë³€ ë² íƒ€ ê³„ì‚° (ì¶”ê°€)\n",
        "    beta_df = compute_rolling_beta(price, volume)\n",
        "\n",
        "    # íŒ©í„°ì™€ ë² íƒ€ í†µí•©\n",
        "    combined_factors = pd.concat([factors, beta_df], axis=1).dropna()\n",
        "\n",
        "    # ì¸ë±ìŠ¤ ì •ë ¬\n",
        "    idx = price.index.intersection(combined_factors.index).intersection(returns.index)\n",
        "\n",
        "    if show_summary:\n",
        "        df_price = None\n",
        "        df_returns = None\n",
        "        df_factors = None\n",
        "\n",
        "        # ê¸°ìˆ í†µê³„ ìš”ì•½ ì¶œë ¥\n",
        "        print(\"\\n[ê¸°ìˆ í†µê³„ ìš”ì•½: Price]\")\n",
        "        print(price.loc[idx].describe().T.round(4))\n",
        "        df_price = price.loc[idx].describe().T.round(4)\n",
        "        df_price.to_excel('df_price.xlsx')\n",
        "\n",
        "        print(\"\\n[ê¸°ìˆ í†µê³„ ìš”ì•½: Returns]\")\n",
        "        print(returns.loc[idx].describe().T.round(4))\n",
        "        df_returns = returns.loc[idx].describe().T.round(4)\n",
        "        df_returns.to_excel('df_returns.xlsx')\n",
        "\n",
        "        print(\"\\n[ê¸°ìˆ í†µê³„ ìš”ì•½: Factors (Momentum, Volatility, Beta ë“±)]\")\n",
        "        print(combined_factors.loc[idx].describe().T.round(4))\n",
        "        df_factors = combined_factors.loc[idx].describe().T.round(4)\n",
        "        df_factors.to_excel('df_factors.xlsx')\n",
        "\n",
        "\n",
        "    return price.loc[idx], returns.loc[idx], combined_factors.loc[idx]\n",
        "\n",
        "# ê°•í™”í•™ìŠµ í™˜ê²½ (ë³´ìƒ ê³„ì‚° ë¡œì§ ìˆ˜ì •: ë² íƒ€ íŒ©í„° í™œìš©)\n",
        "class PPOPortfolioEnv(gym.Env):\n",
        "    def __init__(self, returns, factors, price, objective=\"sharpe\"):\n",
        "        super().__init__()\n",
        "        self.returns = returns\n",
        "        self.factors = factors\n",
        "        self.price = price\n",
        "        self.assets = returns.columns.tolist()\n",
        "        self.n_assets = len(self.assets)\n",
        "        self.window = 20\n",
        "        self.current_step = self.window\n",
        "        self.cash = 1.0\n",
        "        self.asset_quantity = np.zeros(self.n_assets)\n",
        "        self.portfolio_value = [1.0]\n",
        "        self.portfolio_returns = []\n",
        "        self.objective = objective\n",
        "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
        "\n",
        "        # ìƒíƒœ ê³µê°„ í¬ê¸° ìë™ ì¡°ì • (ë² íƒ€ íŒ©í„° ì¶”ê°€ë¡œ ì¸í•´)\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf,\n",
        "            shape=(self.window, factors.shape[1]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = self.window\n",
        "        self.cash = 1.0\n",
        "        self.asset_quantity = np.zeros(self.n_assets)\n",
        "        self.portfolio_value = [1.0]\n",
        "        self.portfolio_returns = []\n",
        "        return self.factors.iloc[self.current_step - self.window:self.current_step].values\n",
        "\n",
        "    def step(self, action):\n",
        "        action = np.clip(action, 0, 1)\n",
        "        action = action / (np.sum(action) + 1e-8)  # í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ ì •ê·œí™”\n",
        "\n",
        "        # í˜„ì¬ ê°€ê²© ë° í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜\n",
        "        price_today = self.price.iloc[self.current_step].values\n",
        "        total_value = self.cash + np.sum(self.asset_quantity * price_today)\n",
        "\n",
        "        # ëª©í‘œ ìì‚° ê°€ì¹˜ ê³„ì‚°\n",
        "        desired_value = action * total_value\n",
        "        current_value = self.asset_quantity * price_today\n",
        "        trade_value = desired_value - current_value\n",
        "\n",
        "        # ê±°ë˜ ë¹„ìš© (0.1% ìˆ˜ìˆ˜ë£Œ)\n",
        "        cost = np.sum(np.abs(trade_value)) * 0.001\n",
        "        net_trade_value = trade_value - np.sign(trade_value) * cost / self.n_assets\n",
        "\n",
        "        # ìì‚° ë° í˜„ê¸ˆ ì—…ë°ì´íŠ¸\n",
        "        self.asset_quantity += net_trade_value / price_today\n",
        "        self.cash = total_value - np.sum(self.asset_quantity * price_today) - cost\n",
        "\n",
        "        # ë‹¤ìŒ ìŠ¤í…ì˜ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ê³„ì‚°\n",
        "        price_next = self.price.iloc[self.current_step + 1].values\n",
        "        port_value_next = self.cash + np.sum(self.asset_quantity * price_next)\n",
        "        port_return = (port_value_next - total_value) / total_value\n",
        "\n",
        "        self.portfolio_returns.append(port_return)\n",
        "        self.portfolio_value.append(port_value_next)\n",
        "        self.current_step += 1\n",
        "\n",
        "        # ì¢…ë£Œ ì¡°ê±´ í™•ì¸\n",
        "        done = self.current_step >= len(self.returns) - 2\n",
        "\n",
        "        # ê´€ì¸¡ê°’ ì—…ë°ì´íŠ¸\n",
        "        obs = self.factors.iloc[self.current_step - self.window:self.current_step].values\n",
        "\n",
        "        # ë³´ìƒ ê³„ì‚° (ë² íƒ€ íŒ©í„° í™œìš© ë°©ì‹ ìˆ˜ì •)\n",
        "        if self.objective == \"sharpe\":\n",
        "            if len(self.portfolio_returns) > 1:\n",
        "                returns_window = np.array(self.portfolio_returns[-20:])\n",
        "                reward = np.mean(returns_window) / (np.std(returns_window) + 1e-6)\n",
        "            else:\n",
        "                reward = 0\n",
        "        elif self.objective == \"beta\":\n",
        "            # ë² íƒ€ íŒ©í„° ì„ íƒ (4ê°œ íŒ©í„° ì¤‘ ëª¨ë©˜í…€ ë² íƒ€ ì‚¬ìš©)\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                # ê° ìì‚°ë³„ beta_mom ê°’ ì„ íƒ\n",
        "                beta_mom = self.factors.iloc[self.current_step - 1].get((asset, 'beta_mom'), 0)\n",
        "                beta_scores.append(beta_mom)\n",
        "            reward = np.dot(action, np.array(beta_scores))\n",
        "\n",
        "        elif self.objective == \"beta_eqw_price\":\n",
        "            # ë² íƒ€ íŒ©í„° ì„ íƒ\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                # ê° ìì‚°ë³„ beta_mom ê°’ ì„ íƒ\n",
        "                beta_mom = self.factors.iloc[self.current_step - 1].get((asset, 'beta_eqw_price'), 0)\n",
        "                beta_scores.append(beta_mom)\n",
        "            reward = np.dot(action, np.array(beta_scores))\n",
        "\n",
        "        elif self.objective == \"beta_eqw_policy\":\n",
        "            # ë² íƒ€ íŒ©í„° ì„ íƒ\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                # ê° ìì‚°ë³„ beta_mom ê°’ ì„ íƒ\n",
        "                beta_mom = self.factors.iloc[self.current_step - 1].get((asset, 'beta_eqw_policy'), 0)\n",
        "                beta_scores.append(beta_mom)\n",
        "            reward = np.dot(action, np.array(beta_scores))\n",
        "\n",
        "        elif self.objective == \"eqw_hybrid\":\n",
        "            eqw_price_scores = []\n",
        "            eqw_policy_scores = []\n",
        "\n",
        "            for asset in self.assets:\n",
        "                eqw_price = self.factors.iloc[self.current_step - 1].get((asset, 'beta_eqw_price'), 0)\n",
        "                eqw_policy = self.factors.iloc[self.current_step - 1].get((asset, 'beta_eqw_policy'), 0)\n",
        "                eqw_price_scores.append(eqw_price)\n",
        "                eqw_policy_scores.append(eqw_policy)\n",
        "\n",
        "            reward_price = np.dot(action, np.array(eqw_price_scores))\n",
        "            reward_policy = np.dot(action, np.array(eqw_policy_scores))\n",
        "            reward = 0.5 * reward_price + 0.5 * reward_policy\n",
        "\n",
        "\n",
        "        elif self.objective == \"momvol\":\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                # ëª¨ë©˜í…€: ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ\n",
        "                mom = self.factors.iloc[self.current_step - 1].get((asset, 'beta_mom'), 0)\n",
        "                # ë³€ë™ì„±: ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ ìŒìˆ˜ ë¶€í˜¸\n",
        "                vol = self.factors.iloc[self.current_step - 1].get((asset, 'beta_vol'), 0)\n",
        "\n",
        "                # ì¡°í•©: ëª¨ë©˜í…€ - Î± * ë³€ë™ì„± (ex. Î±=1, í˜¹ì€ íŠœë‹) beta_volì´ ìŒìˆ˜ë¡œ ë˜ì–´ ìˆìŒ\n",
        "                score = mom + vol\n",
        "                beta_scores.append(score)\n",
        "\n",
        "            reward = np.dot(action, np.array(beta_scores))\n",
        "\n",
        "        elif self.objective == \"multi_beta\":\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                beta_total = 0\n",
        "                for factor_name in [\"beta_mom\", \"beta_vol\", \"beta_ma\", \"beta_volz\", \"beta_sharpe\", \"beta_mdd\",\"beta_eqw_price\",\"beta_eqw_policy\"]:\n",
        "                    beta_val = self.factors.iloc[self.current_step - 1].get((asset, factor_name), 0)\n",
        "                    beta_total += beta_val\n",
        "                beta_scores.append(beta_total / len(mixed_assets))  # ë‹¨ìˆœ í‰ê· \n",
        "            reward = np.dot(action, np.array(beta_scores))\n",
        "\n",
        "        elif self.objective == \"hybrid\":\n",
        "            if len(self.portfolio_returns) > 1:\n",
        "                returns_window = np.array(self.portfolio_returns[-20:])\n",
        "                sharpe = np.mean(returns_window) / (np.std(returns_window) + 1e-6)\n",
        "            else:\n",
        "                sharpe = 0\n",
        "\n",
        "            # ë² íƒ€ íŒ©í„° ì„ íƒ (4ê°œ íŒ©í„° ì¤‘ ëª¨ë©˜í…€ ë² íƒ€ ì‚¬ìš©)\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                beta_mom = self.factors.iloc[self.current_step - 1].get((asset, 'beta_mom'), 0)\n",
        "                beta_scores.append(beta_mom)\n",
        "            beta = np.dot(action, np.array(beta_scores))\n",
        "            reward = 0.5 * sharpe + 0.5 * beta\n",
        "\n",
        "        elif self.objective == \"multi_hybrid\":\n",
        "            if len(self.portfolio_returns) > 1:\n",
        "                returns_window = np.array(self.portfolio_returns[-20:])\n",
        "                sharpe = np.mean(returns_window) / (np.std(returns_window) + 1e-6)\n",
        "            else:\n",
        "                sharpe = 0\n",
        "\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                beta_total = 0\n",
        "                for factor_name in [\"beta_mom\", \"beta_vol\", \"beta_ma\", \"beta_volz\", \"beta_sharpe\", \"beta_mdd\",\"beta_eqw_price\",\"beta_eqw_policy\"]:\n",
        "                    beta_val = self.factors.iloc[self.current_step - 1].get((asset, factor_name), 0)\n",
        "                    beta_total += beta_val\n",
        "                beta_scores.append(beta_total / len(mixed_assets))\n",
        "            beta = np.dot(action, np.array(beta_scores))\n",
        "            reward = 0.5 * sharpe + 0.5 * beta\n",
        "\n",
        "        elif self.objective == \"factor_weighted\":\n",
        "            perf_scores = []\n",
        "            risk_scores = []\n",
        "\n",
        "            for asset in self.assets:\n",
        "                # ì„±ê³¼í˜•\n",
        "                beta_mom = self.factors.iloc[self.current_step - 1].get((asset, \"beta_mom\"), 0)\n",
        "                beta_sharpe = self.factors.iloc[self.current_step - 1].get((asset, \"beta_sharpe\"), 0)\n",
        "                perf_score = np.mean([beta_mom, beta_sharpe])\n",
        "                perf_scores.append(perf_score)\n",
        "\n",
        "                # ì•ˆì •í˜•\n",
        "                beta_vol = self.factors.iloc[self.current_step - 1].get((asset, \"beta_vol\"), 0)\n",
        "                beta_mdd = self.factors.iloc[self.current_step - 1].get((asset, \"beta_mdd\"), 0)\n",
        "                beta_volz = self.factors.iloc[self.current_step - 1].get((asset, \"beta_volz\"), 0)\n",
        "                risk_score = np.mean([beta_vol, beta_mdd, beta_volz])\n",
        "                risk_scores.append(risk_score)\n",
        "\n",
        "            # ê°€ì¤‘ì¹˜ ì„¤ì •\n",
        "            w_perf = 0.9\n",
        "            w_risk = 0.1\n",
        "\n",
        "            reward = w_perf * np.dot(action, np.array(perf_scores)) + w_risk * np.dot(action, np.array(risk_scores))\n",
        "\n",
        "        elif self.objective == \"eqw_similarity\":\n",
        "            eqw_weights = np.ones_like(action) / len(action)\n",
        "            distance = np.linalg.norm(action - eqw_weights, ord=1)  # L1 norm\n",
        "            reward = 1 - distance  # ìœ ì‚¬í• ìˆ˜ë¡ ë³´ìƒ â†‘\n",
        "\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown objective: {self.objective}\")\n",
        "\n",
        "\n",
        "\n",
        "        return obs, reward, done, {\"portfolio_value\": port_value_next}\n",
        "\n",
        "def equal_weight_backtest(price, transaction_cost=0.001):\n",
        "    \"\"\"\n",
        "    ë§¤ì¼ ë¦¬ë°¸ëŸ°ì‹± + ìˆ˜ìˆ˜ë£Œ ë°˜ì˜ + ìì‚° ë³´ìœ ëŸ‰ ê¸°ë°˜ ë°±í…ŒìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    returns = price.pct_change().dropna()\n",
        "    n_assets = returns.shape[1]\n",
        "    weights = np.ones(n_assets) / n_assets\n",
        "    portfolio_values = []\n",
        "    asset_quantity = np.zeros(n_assets)\n",
        "    cash = 1.0  # ì´ˆê¸° ìë³¸\n",
        "\n",
        "    for t in range(1, len(returns)):\n",
        "        prices_today = price.iloc[t - 1].values\n",
        "        total_value = cash + np.sum(asset_quantity * prices_today)\n",
        "\n",
        "        desired_value = total_value * weights\n",
        "        current_value = asset_quantity * prices_today\n",
        "        trade_value = desired_value - current_value\n",
        "\n",
        "        turnover = np.sum(np.abs(trade_value))\n",
        "        cost = turnover * transaction_cost\n",
        "\n",
        "        # ê±°ë˜ ë°˜ì˜\n",
        "        net_trade_value = trade_value - np.sign(trade_value) * cost / n_assets\n",
        "        asset_quantity += net_trade_value / prices_today\n",
        "        cash = total_value - np.sum(asset_quantity * prices_today) - cost\n",
        "\n",
        "        # í•˜ë£¨ í›„ ê°€ì¹˜ ê³„ì‚°\n",
        "        prices_next = price.iloc[t].values\n",
        "        portfolio_value = cash + np.sum(asset_quantity * prices_next)\n",
        "        portfolio_values.append(portfolio_value)\n",
        "\n",
        "    return pd.Series(portfolio_values, index=returns.index[1:])\n",
        "\n",
        "\n",
        "def mvp_daily_rebalancing(price, lookback=60, transaction_cost=0.001):\n",
        "    \"\"\"\n",
        "    MVP ì „ëµ ê¸°ë°˜ ì¼ì¼ ë¦¬ë°¸ëŸ°ì‹± ë°±í…ŒìŠ¤íŠ¸ (ì •í™•í•œ ë¦¬ë°¸ëŸ°ì‹± ë°˜ì˜)\n",
        "    \"\"\"\n",
        "    returns = price.pct_change().dropna()\n",
        "    portfolio_values = []\n",
        "    asset_quantity = np.zeros(len(price.columns))\n",
        "    cash = 1.0\n",
        "\n",
        "    for t in range(lookback, len(price) - 1):\n",
        "        window_price = price.iloc[t - lookback:t]\n",
        "        price_today = price.iloc[t].values\n",
        "\n",
        "        try:\n",
        "            mu = expected_returns.mean_historical_return(window_price, frequency=252)\n",
        "            S = risk_models.sample_cov(window_price, frequency=252)\n",
        "            ef = EfficientFrontier(mu, S)\n",
        "            ef.min_volatility()\n",
        "            weights = ef.clean_weights()\n",
        "            w = np.array([weights.get(ticker, 0.0) for ticker in price.columns])\n",
        "        except:\n",
        "            w = np.ones(len(price.columns)) / len(price.columns)\n",
        "\n",
        "        total_value = cash + np.sum(asset_quantity * price_today)\n",
        "\n",
        "        desired_value = w * total_value\n",
        "        current_value = asset_quantity * price_today\n",
        "        trade_value = desired_value - current_value\n",
        "\n",
        "        # ìˆ˜ìˆ˜ë£Œ ê³„ì‚° ë° ë°˜ì˜\n",
        "        turnover = np.sum(np.abs(trade_value))\n",
        "        cost = turnover * transaction_cost\n",
        "\n",
        "        asset_quantity += trade_value / price_today\n",
        "        cash = total_value - np.sum(asset_quantity * price_today) - cost\n",
        "\n",
        "        # ë‹¤ìŒ ë‚  í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜\n",
        "        price_next = price.iloc[t + 1].values\n",
        "        portfolio_value = cash + np.sum(asset_quantity * price_next)\n",
        "\n",
        "        portfolio_values.append(portfolio_value)\n",
        "\n",
        "    index = price.index[lookback + 1:]\n",
        "    return pd.Series(portfolio_values, index=index)\n",
        "\n",
        "def equal_weight_buy_and_hold(price: pd.DataFrame, transaction_cost: float = 0.001) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Equal Weight Buy & Hold ì „ëµ (ë¦¬ë°¸ëŸ°ì‹± ì—†ìŒ)\n",
        "    - ì´ˆê¸° ìì‚°ì„ ë™ì¼ ë¹„ì¤‘ìœ¼ë¡œ ê° ìì‚°ì— ë¶„ë°° í›„ ë³´ìœ \n",
        "    - ìˆ˜ìˆ˜ë£ŒëŠ” ìµœì´ˆ ë§¤ìˆ˜ ì‹œì ì—ë§Œ ì ìš©\n",
        "    \"\"\"\n",
        "    n_assets = price.shape[1]\n",
        "    price = price.dropna()\n",
        "    start_price = price.iloc[0].values\n",
        "\n",
        "    weights = np.ones(n_assets) / n_assets\n",
        "    total_value = 1.0\n",
        "    turnover = np.sum(np.abs(weights * total_value))\n",
        "    cost = turnover * transaction_cost\n",
        "    effective_value = total_value - cost\n",
        "\n",
        "    # ì´ˆê¸° ë§¤ìˆ˜\n",
        "    desired_value = weights * effective_value\n",
        "    asset_quantity = desired_value / start_price\n",
        "\n",
        "    portfolio_values = []\n",
        "    for t in range(len(price)):\n",
        "        price_today = price.iloc[t].values\n",
        "        port_val = np.sum(asset_quantity * price_today)\n",
        "        portfolio_values.append(port_val)\n",
        "\n",
        "    return pd.Series(portfolio_values, index=price.index)\n",
        "\n",
        "\n",
        "# í›ˆë ¨ ë° í‰ê°€ í•¨ìˆ˜ (ìˆ˜ì •: í‰ê°€ í™˜ê²½ ê°œì„ )\n",
        "def train_and_evaluate(assets, algo_class, objective=\"sharpe\"):\n",
        "    price, returns, factors = fetch_data(assets)\n",
        "\n",
        "\n",
        "    if algo_class is None:\n",
        "        if objective == \"equal_weights\":\n",
        "            return equal_weight_backtest(price[assets], transaction_cost=0.001)\n",
        "        elif objective == \"mvp\":\n",
        "            return mvp_daily_rebalancing(price[assets], lookback=60, transaction_cost=0.001)\n",
        "        elif objective == \"buy_and_hold\":\n",
        "            return equal_weight_buy_and_hold(price[assets], lookback=60, transaction_cost=0.001)\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        env = DummyVecEnv([lambda: PPOPortfolioEnv(returns, factors, price, objective)])\n",
        "        model = algo_class(\"MlpPolicy\", env, verbose=0, seed=SEED)\n",
        "        model.learn(total_timesteps=50000)\n",
        "\n",
        "        # ëª¨ë¸ ì €ì¥\n",
        "        #model_path = os.path.join(MODEL_DIR, f\"ppo_{algo_class}_{objective}_model.zip\")\n",
        "        #model.save(model_path)\n",
        "        #print(f\"[ì €ì¥ ì™„ë£Œ] {model_path}\")\n",
        "\n",
        "\n",
        "        # í‰ê°€\n",
        "        env_eval = PPOPortfolioEnv(returns, factors, price, objective)\n",
        "        obs = env_eval.reset()\n",
        "        values = [env_eval.portfolio_value[0]]\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            action, _ = model.predict(obs)\n",
        "            obs, reward, done, info = env_eval.step(action)\n",
        "            values.append(info[\"portfolio_value\"])\n",
        "\n",
        "        index = price.index[env_eval.window:env_eval.window + len(values)]\n",
        "        return pd.Series(values, index=index)\n",
        "\n",
        "\n",
        "# ì„±ê³¼ ì§€í‘œ ê³„ì‚° (ìˆ˜ì •: ì˜¬ë°”ë¥¸ ì—°ê°„í™” ê³„ì‚°)\n",
        "# ì„±ê³¼ ì§€í‘œ ê³„ì‚°\n",
        "def performance_metrics(series):\n",
        "    returns = series.pct_change().dropna()\n",
        "    cumulative_return = series.iloc[-1] / series.iloc[0] - 1\n",
        "    annualized_return = (series.iloc[-1] / series.iloc[0]) ** (252 / len(series)) - 1\n",
        "    cagr = annualized_return  # ì¤‘ë³µ ì œê±°\n",
        "    annualized_vol = returns.std() * np.sqrt(252)\n",
        "    sharpe = (cagr - 0.0) / (annualized_vol + 1e-6)\n",
        "    downside_std = returns[returns < 0].std() * np.sqrt(252)\n",
        "    sortino = (cagr - 0.0) / (downside_std + 1e-6)\n",
        "    peak = series.cummax()\n",
        "    drawdown = (series - peak) / peak\n",
        "    mdd = drawdown.min()\n",
        "    mdd = drawdown.min()\n",
        "    if len(returns) == 0:\n",
        "        turnover = 0.0\n",
        "    else:\n",
        "        turnover = (np.abs(returns).sum()) / len(returns)\n",
        "\n",
        "    return {\n",
        "        \"Sharpe Ratio\": sharpe,\n",
        "        \"Sortino Ratio\": sortino,\n",
        "        \"Cumulative Return\": cumulative_return,\n",
        "        \"Annualized Return\": cagr,\n",
        "        \"Annualized Volatility\": annualized_vol,\n",
        "        \"CAGR\": cagr,\n",
        "        \"Maximum Drawdown\": mdd,\n",
        "        \"Turnover Ratio\": turnover\n",
        "    }\n",
        "\n",
        "# XAI (SHAP í•´ì„) í•¨ìˆ˜ ì¶”ê°€\n",
        "import shap\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "def run_shap_feature_importance_with_summary(factors, returns, target_asset=\"BTC-USD\", sample_size=500):\n",
        "    \"\"\"\n",
        "    SHAP ë¶„ì„ì„ í†µí•´ ê° íŒ©í„°ê°€ ìˆ˜ìµë¥ ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹œê°í™”í•˜ê³ ,\n",
        "    Mean |SHAP value| ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì¹˜ ìš”ì•½ ê²°ê³¼ë¥¼ ë°˜í™˜\n",
        "    \"\"\"\n",
        "    # ë°ì´í„° ì •ë¦¬\n",
        "    y = returns[target_asset].dropna()\n",
        "    X = factors.loc[y.index].copy()\n",
        "    X = X.dropna()\n",
        "    y = y.loc[X.index]\n",
        "\n",
        "    # ìƒ˜í”Œ ìˆ˜ ì œí•œ\n",
        "    if sample_size is not None and len(X) > sample_size:\n",
        "        X, _, y, _ = train_test_split(X, y, train_size=sample_size, random_state=42)\n",
        "\n",
        "    # ëª¨ë¸ í•™ìŠµ\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # SHAP ê³„ì‚°\n",
        "    explainer = shap.Explainer(model.predict, X)\n",
        "    shap_values = explainer(X)\n",
        "\n",
        "    # ì‹œê°í™” (beeswarm í˜•ì‹)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shap.summary_plot(shap_values, X, plot_type=\"dot\", show=True)\n",
        "\n",
        "    # ğŸ“Š í‰ê·  SHAP ê°’ ê³„ì‚° (ë…¼ë¬¸ìš© í•´ì„)\n",
        "    mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
        "    shap_importance = pd.DataFrame({\n",
        "        \"Factor\": X.columns,\n",
        "        \"Mean|SHAP|\": mean_abs_shap\n",
        "    }).sort_values(by=\"Mean|SHAP|\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n[SHAP íŒ©í„° ì¤‘ìš”ë„ ìš”ì•½ (Mean Absolute SHAP Values)]\")\n",
        "    print(shap_importance.to_string(index=False))\n",
        "\n",
        "    return shap_importance\n",
        "\n",
        "\n",
        "# ì‹¤í—˜ êµ¬ì„±\n",
        "experiments = [\n",
        "#    (\"Crypto\", crypto_assets, \"EqualWeight\", None, \"equal_weights\"),\n",
        "#    (\"Crypto\", crypto_assets, \"MeanVariance\", None, \"mvp\"),\n",
        "#    (\"Crypto\", crypto_assets, \"PPO\", PPO, \"sharpe\"),\n",
        "#    (\"Crypto\", crypto_assets, \"PPO\", PPO, \"beta\"),\n",
        "#    (\"Crypto\", crypto_assets, \"PPO\", PPO, \"multi_beta\"),\n",
        "#   (\"Crypto\", crypto_assets, \"PPO\", PPO, \"hybrid\"),\n",
        "#    (\"Crypto\", crypto_assets, \"PPO\", PPO, \"mulit_hybrid\"),\n",
        "##    (\"Crypto\", crypto_assets, \"SAC\", SAC, \"sharpe\"),\n",
        "#    (\"Crypto\", crypto_assets, \"SAC\", SAC, \"beta\"),\n",
        "#    (\"Crypto\", crypto_assets, \"SAC\", SAC, \"hybrid\"),\n",
        "#    (\"Crypto\", crypto_assets, \"TD3\", TD3, \"sharpe\"),\n",
        "#    (\"Crypto\", crypto_assets, \"TD3\", TD3, \"beta\"),\n",
        "#    (\"Crypto\", crypto_assets, \"TD3\", TD3, \"hybrid\"),\n",
        "#    (\"Crypto\", crypto_assets, \"TD3\", TD3, \"mulit_hybrid\"),\n",
        "\n",
        "#    (\"Stock\", stock_assets, \"PPO\", PPO, \"sharpe\"),\n",
        "#    (\"Stock\", stock_assets, \"PPO\", PPO, \"beta\"),\n",
        "#    (\"Stock\", stock_assets, \"PPO\", PPO, \"multi_beta\"),\n",
        "#    (\"Stock\", stock_assets, \"PPO\", PPO, \"hybrid\"),\n",
        "#    (\"Stock\", stock_assets, \"PPO\", PPO, \"multi_hybrid\"),\n",
        "#    (\"Stock\", stock_assets, \"SAC\", SAC, \"sharpe\"),\n",
        "#    (\"Stock\", stock_assets, \"SAC\", SAC, \"beta\"),\n",
        "#    (\"Stock\", stock_assets, \"SAC\", SAC, \"multi_beta\"),\n",
        "#    (\"Stock\", stock_assets, \"SAC\", SAC, \"hybrid\"),\n",
        "#    (\"Stock\", stock_assets, \"SAC\", SAC, \"multi_hybrid\"),\n",
        "                #    (\"Stock\", stock_assets, \"TD3\", TD3, \"sharpe\"),\n",
        "#    (\"Stock\", stock_assets, \"TD3\", TD3, \"beta\"),\n",
        "#    (\"Stock\", stock_assets, \"TD3\", TD3, \"hybrid\"),\n",
        "\n",
        "#    (\"Mixed\", mixed_assets, \"EqualWeight\", None, \"equal_weights\"),\n",
        "    (\"Mixed\", mixed_assets, \"BuyandHold\", None, \"buy_and_hold\"),\n",
        "    (\"Mixed\", mixed_assets, \"MeanVariance\", None, \"mvp\"),\n",
        "    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"sharpe\"),\n",
        "    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"beta_eqw_price\"),\n",
        "    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"beta_eqw_policy\"),\n",
        "    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"eqw_hybrid\"),\n",
        "#    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"beta\"),\n",
        "#    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"multi_beta\"),\n",
        "#   (\"Mixed\", mixed_assets, \"PPO\", PPO, \"momvol\"),\n",
        "#    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"hybrid\"),\n",
        "    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"multi_hybrid\"),\n",
        "#    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"eqw_similarity\"),\n",
        "\n",
        "#    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"factor_weighted\"),\n",
        "\n",
        "\n",
        "#    (\"Mixed\", mixed_assets, \"SAC\", SAC, \"sharpe\"),\n",
        "#    (\"Mixed\", mixed_assets, \"SAC\", SAC, \"beta\"),\n",
        "#     (\"Mixed\", mixed_assets, \"SAC\", SAC, \"multi_beta\"),\n",
        "#    (\"Mixed\", mixed_assets, \"SAC\", SAC, \"hybrid\"),\n",
        "#     (\"Mixed\", mixed_assets, \"SAC\", SAC, \"mulit_hybrid\"),\n",
        "#    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"sharpe\"),\n",
        "#    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"beta\"),\n",
        "#    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"hybrid\"),\n",
        "#    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"multi_beta\"),\n",
        "#    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"multi_hybrid\"),\n",
        "#    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"factor_weighted\"),\n",
        "]\n",
        "\n",
        "# ì‹¤í—˜ ì‹¤í–‰\n",
        "results = {}\n",
        "previous_group = None\n",
        "\n",
        "for group, assets, algo_name, algo_class, objective in experiments:\n",
        "    key = f\"{group}_{algo_name}_{objective}\"\n",
        "    print(f\"â–¶ Running: {key}\")\n",
        "    try:\n",
        "        results[key] = train_and_evaluate(assets, algo_class, objective)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in {key}: {str(e)}\")\n",
        "        results[key] = None\n",
        "    # ê·¸ë£¹ì´ ë°”ë€”ë•Œë§Œ ê¸°ìˆ í†µê³„ ì¶œë ¥\n",
        "    if previous_group != group:\n",
        "        show_summary = True\n",
        "        previous_group = group\n",
        "    else:\n",
        "        show_summary = False\n",
        "\n",
        "\n",
        "# ì„±ê³¼ ìš”ì•½ (ì˜¤ë¥˜ ì œì™¸)\n",
        "valid_results = {k: v for k, v in results.items() if v is not None}\n",
        "metrics_table = pd.DataFrame({k: performance_metrics(v) for k, v in valid_results.items()}).T\n",
        "print(metrics_table)\n",
        "\n",
        "# ì„±ê³¼ ë§‰ëŒ€ê·¸ë˜í”„\n",
        "metrics_table[[\"Cumulative Return\", \"Sharpe Ratio\", \"Maximum Drawdown\"]].plot(\n",
        "    kind=\"bar\", figsize=(12, 6), title=\"Asset Group Performance (by RL & Objective)\"\n",
        ")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ì‹œê³„ì—´ ê·¸ë˜í”„\n",
        "results_df = pd.DataFrame(valid_results)\n",
        "results_df.plot(figsize=(12, 6), title=\"Portfolio Value Comparison\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# sharpe ë¥¼ baselineìœ¼ë¡œ í•˜ì—¬ í†µê³„ì ìœ¼ë¡œ ì˜ë¯¸ê°€ ìˆëŠ”ì§€ ë¹„êµí•¨\n",
        "summary = []\n",
        "\n",
        "for (group, assets, algo, model_cls, obj) in experiments:\n",
        "    if obj == \"sharpe\":\n",
        "        continue  # baseline ì œì™¸\n",
        "\n",
        "    base_key = f\"{group}_{algo}_sharpe\"\n",
        "    compare_key = f\"{group}_{algo}_{obj}\"\n",
        "\n",
        "    # Add check for None before calling compare_strategies\n",
        "    if base_key in results and compare_key in results and results[base_key] is not None and results[compare_key] is not None:\n",
        "        res = compare_strategies(results[base_key], results[compare_key], label1=base_key, label2=compare_key)\n",
        "        summary.append({\n",
        "            \"Group\": group,\n",
        "            \"Algorithm\": algo,\n",
        "            \"CompareWith\": obj,\n",
        "            \"t_p\": res[\"t_p\"],\n",
        "            \"u_p\": res[\"u_p\"]\n",
        "        })\n",
        "\n",
        "summary_df = pd.DataFrame(summary)\n",
        "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"Comparison Results\", dataframe=summary_df)\n",
        "print(summary_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPeFERh5SsNV",
        "outputId": "1f28e778-2dbc-4a5c-ce1d-d1c540110587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AAPL', 'MSFT', 'TSLA', 'SPY', 'BTC-USD', 'TLT', 'GLD']\n",
            "â–¶ Running: Mixed_BuyandHold_buy_and_hold\n",
            "\n",
            "[ê¸°ìˆ í†µê³„ ìš”ì•½: Price]\n",
            "          count        mean         std        min         25%         50%  \\\n",
            "Ticker                                                                       \n",
            "AAPL     2292.0    144.7144     54.2241    41.6182    113.8836    147.9880   \n",
            "BTC-USD  2292.0  37534.0009  27157.6107  3963.0706  12115.1929  30192.7949   \n",
            "GLD      2292.0    183.0520     39.9723   119.9400    162.6200    173.6250   \n",
            "MSFT     2292.0    278.7280     99.3044   110.1081    205.3097    270.1886   \n",
            "SPY      2292.0    404.6328     99.3406   206.6833    322.9774    397.8985   \n",
            "TLT      2292.0    109.5597     20.1259    77.3489     90.4393    105.2849   \n",
            "TSLA     2292.0    197.2247    105.8469    11.9313    136.5407    216.1200   \n",
            "\n",
            "                75%          max  \n",
            "Ticker                            \n",
            "AAPL       181.5610     258.3967  \n",
            "BTC-USD  56174.4121  111673.2812  \n",
            "GLD        187.4625     316.2900  \n",
            "MSFT       366.4874     497.4500  \n",
            "SPY        451.8507     614.9100  \n",
            "TLT        126.7272     149.7590  \n",
            "TSLA       262.3400     479.8600  \n",
            "\n",
            "[ê¸°ìˆ í†µê³„ ìš”ì•½: Returns]\n",
            "          count    mean     std     min     25%     50%     75%     max\n",
            "Ticker                                                                 \n",
            "AAPL     2292.0  0.0008  0.0165 -0.1286 -0.0034  0.0000  0.0062  0.1533\n",
            "BTC-USD  2292.0  0.0020  0.0336 -0.3717 -0.0130  0.0007  0.0163  0.1875\n",
            "GLD      2292.0  0.0004  0.0081 -0.0537 -0.0019  0.0000  0.0036  0.0485\n",
            "MSFT     2292.0  0.0008  0.0153 -0.1474 -0.0030  0.0000  0.0059  0.1422\n",
            "SPY      2292.0  0.0004  0.0107 -0.1094 -0.0017  0.0000  0.0038  0.1050\n",
            "TLT      2292.0 -0.0000  0.0089 -0.0667 -0.0035  0.0000  0.0033  0.0752\n",
            "TSLA     2292.0  0.0018  0.0345 -0.2106 -0.0082  0.0000  0.0124  0.2269\n",
            "\n",
            "[ê¸°ìˆ í†µê³„ ìš”ì•½: Factors (Momentum, Volatility, Beta ë“±)]\n",
            "                          count    mean     std     min     25%     50%  \\\n",
            "AAPL_mom                 2292.0  0.0157  0.0668 -0.2328 -0.0266  0.0203   \n",
            "BTC-USD_mom              2292.0  0.0417  0.1645 -0.4868 -0.0529  0.0204   \n",
            "GLD_mom                  2292.0  0.0087  0.0338 -0.0864 -0.0132  0.0071   \n",
            "MSFT_mom                 2292.0  0.0148  0.0565 -0.2213 -0.0196  0.0171   \n",
            "SPY_mom                  2292.0  0.0085  0.0427 -0.2560 -0.0123  0.0151   \n",
            "...                         ...     ...     ...     ...     ...     ...   \n",
            "(TSLA, beta_volz)        2292.0  0.0023  0.0320 -0.1098 -0.0160  0.0041   \n",
            "(TSLA, beta_sharpe)      2292.0  0.0529  0.1509 -0.3315 -0.0638  0.0439   \n",
            "(TSLA, beta_mdd)         2292.0  0.7843  0.1149  0.3937  0.7281  0.8031   \n",
            "(TSLA, beta_eqw_price)   2292.0  0.8629  0.0029  0.8582  0.8607  0.8625   \n",
            "(TSLA, beta_eqw_policy)  2292.0  0.0742  0.0000  0.0742  0.0742  0.0742   \n",
            "\n",
            "                            75%     max  \n",
            "AAPL_mom                 0.0626  0.2440  \n",
            "BTC-USD_mom              0.1205  0.7157  \n",
            "GLD_mom                  0.0285  0.1397  \n",
            "MSFT_mom                 0.0480  0.2247  \n",
            "SPY_mom                  0.0315  0.2478  \n",
            "...                         ...     ...  \n",
            "(TSLA, beta_volz)        0.0247  0.1034  \n",
            "(TSLA, beta_sharpe)      0.1620  0.4543  \n",
            "(TSLA, beta_mdd)         0.8736  0.9614  \n",
            "(TSLA, beta_eqw_price)   0.8650  0.8724  \n",
            "(TSLA, beta_eqw_policy)  0.0742  0.0742  \n",
            "\n",
            "[70 rows x 8 columns]\n",
            "Error in Mixed_BuyandHold_buy_and_hold: equal_weight_buy_and_hold() got an unexpected keyword argument 'lookback'\n",
            "â–¶ Running: Mixed_MeanVariance_mvp\n",
            "\n",
            "[ê¸°ìˆ í†µê³„ ìš”ì•½: Price]\n",
            "          count        mean         std        min         25%         50%  \\\n",
            "Ticker                                                                       \n",
            "AAPL     2292.0    144.7144     54.2241    41.6182    113.8836    147.9880   \n",
            "BTC-USD  2292.0  37534.0036  27157.6176  3963.0706  12115.1929  30192.7949   \n",
            "GLD      2292.0    183.0520     39.9723   119.9400    162.6200    173.6250   \n",
            "MSFT     2292.0    278.7280     99.3044   110.1081    205.3098    270.1886   \n",
            "SPY      2292.0    404.6328     99.3406   206.6833    322.9775    397.8985   \n",
            "TLT      2292.0    109.5597     20.1259    77.3488     90.4393    105.2849   \n",
            "TSLA     2292.0    197.2247    105.8469    11.9313    136.5407    216.1200   \n",
            "\n",
            "                75%          max  \n",
            "Ticker                            \n",
            "AAPL       181.5610     258.3967  \n",
            "BTC-USD  56174.4121  111673.2812  \n",
            "GLD        187.4625     316.2900  \n",
            "MSFT       366.4874     497.4500  \n",
            "SPY        451.8507     614.9100  \n",
            "TLT        126.7272     149.7590  \n",
            "TSLA       262.3400     479.8600  \n",
            "\n",
            "[ê¸°ìˆ í†µê³„ ìš”ì•½: Returns]\n",
            "          count    mean     std     min     25%     50%     75%     max\n",
            "Ticker                                                                 \n",
            "AAPL     2292.0  0.0008  0.0165 -0.1286 -0.0034  0.0000  0.0062  0.1533\n",
            "BTC-USD  2292.0  0.0020  0.0336 -0.3717 -0.0130  0.0007  0.0163  0.1875\n",
            "GLD      2292.0  0.0004  0.0081 -0.0537 -0.0019  0.0000  0.0036  0.0485\n",
            "MSFT     2292.0  0.0008  0.0153 -0.1474 -0.0030  0.0000  0.0059  0.1422\n",
            "SPY      2292.0  0.0004  0.0107 -0.1094 -0.0017  0.0000  0.0038  0.1050\n",
            "TLT      2292.0 -0.0000  0.0089 -0.0667 -0.0035  0.0000  0.0033  0.0752\n",
            "TSLA     2292.0  0.0018  0.0345 -0.2106 -0.0082  0.0000  0.0124  0.2269\n",
            "\n",
            "[ê¸°ìˆ í†µê³„ ìš”ì•½: Factors (Momentum, Volatility, Beta ë“±)]\n",
            "                          count    mean     std     min     25%     50%  \\\n",
            "AAPL_mom                 2292.0  0.0157  0.0668 -0.2328 -0.0266  0.0203   \n",
            "BTC-USD_mom              2292.0  0.0417  0.1645 -0.4868 -0.0529  0.0204   \n",
            "GLD_mom                  2292.0  0.0087  0.0338 -0.0864 -0.0132  0.0071   \n",
            "MSFT_mom                 2292.0  0.0148  0.0565 -0.2213 -0.0196  0.0171   \n",
            "SPY_mom                  2292.0  0.0085  0.0427 -0.2560 -0.0123  0.0151   \n",
            "...                         ...     ...     ...     ...     ...     ...   \n",
            "(TSLA, beta_volz)        2292.0  0.0023  0.0320 -0.1098 -0.0160  0.0041   \n",
            "(TSLA, beta_sharpe)      2292.0  0.0529  0.1509 -0.3315 -0.0638  0.0439   \n",
            "(TSLA, beta_mdd)         2292.0  0.7843  0.1149  0.3937  0.7281  0.8031   \n",
            "(TSLA, beta_eqw_price)   2292.0  0.8629  0.0029  0.8582  0.8607  0.8625   \n",
            "(TSLA, beta_eqw_policy)  2292.0  0.0742  0.0000  0.0742  0.0742  0.0742   \n",
            "\n",
            "                            75%     max  \n",
            "AAPL_mom                 0.0626  0.2440  \n",
            "BTC-USD_mom              0.1205  0.7157  \n",
            "GLD_mom                  0.0285  0.1397  \n",
            "MSFT_mom                 0.0480  0.2247  \n",
            "SPY_mom                  0.0315  0.2478  \n",
            "...                         ...     ...  \n",
            "(TSLA, beta_volz)        0.0247  0.1034  \n",
            "(TSLA, beta_sharpe)      0.1620  0.4543  \n",
            "(TSLA, beta_mdd)         0.8736  0.9614  \n",
            "(TSLA, beta_eqw_price)   0.8650  0.8724  \n",
            "(TSLA, beta_eqw_policy)  0.0742  0.0742  \n",
            "\n",
            "[70 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_shap_feature_importance(factors, returns, target_asset=\"BTC-USD\", sample_size=1000):\n",
        "    try:\n",
        "        # 1. ëŒ€ìƒ ìì‚°ì— í•´ë‹¹í•˜ëŠ” íŒ©í„° ì»¬ëŸ¼ ì„ íƒ\n",
        "        if isinstance(factors.columns[0], tuple):\n",
        "            target_cols = [col for col in factors.columns if col[0] == target_asset]\n",
        "        else:\n",
        "            target_cols = [col for col in factors.columns if str(col).startswith(target_asset)]\n",
        "\n",
        "        if not target_cols:\n",
        "            print(f\"[Error] {target_asset} ê´€ë ¨ íŒ©í„° ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "\n",
        "        # 2. X, y êµ¬ì„±\n",
        "        X = factors[target_cols].dropna()\n",
        "        y = returns[target_asset].loc[X.index]\n",
        "\n",
        "        # 3. X ì»¬ëŸ¼ ì´ë¦„ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì¤‘ìš”!!)\n",
        "        if isinstance(X.columns[0], tuple):\n",
        "            X.columns = ['_'.join(col) for col in X.columns]\n",
        "\n",
        "        # 4. ìƒ˜í”Œ ìˆ˜ ì œí•œ\n",
        "        if sample_size and len(X) > sample_size:\n",
        "            X, _, y, _ = train_test_split(X, y, train_size=sample_size, random_state=42)\n",
        "\n",
        "        # 5. ëª¨ë¸ í•™ìŠµ\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # 6. SHAP ë¶„ì„\n",
        "        explainer = shap.Explainer(model, X)\n",
        "        shap_values = explainer(X)\n",
        "\n",
        "        # 7. SHAP summary plot\n",
        "        shap.summary_plot(shap_values, X, plot_type=\"dot\")\n",
        "\n",
        "        # 8. í‰ê·  SHAP ê°’ í‘œ ì¶œë ¥\n",
        "        mean_shap = pd.DataFrame({\n",
        "            \"Factor\": X.columns,\n",
        "            \"Mean |SHAP|\": np.abs(shap_values.values).mean(axis=0)\n",
        "        }).sort_values(by=\"Mean |SHAP|\", ascending=False)\n",
        "\n",
        "        print(mean_shap.round(4))\n",
        "        return mean_shap\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ì˜¤ë¥˜] {target_asset}ì— ëŒ€í•œ SHAP ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n"
      ],
      "metadata": {
        "id": "bmSfBaAuajJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_shap_feature_importance_all_factors(factors, returns, target_asset, sample_size=1000):\n",
        "    try:\n",
        "        # 1. ëª¨ë“  factorë¥¼ ì‚¬ìš©\n",
        "        X = factors.dropna()\n",
        "        y = returns[target_asset].loc[X.index]\n",
        "\n",
        "        # ğŸ” ëª¨ë“  ì»¬ëŸ¼ ì´ë¦„ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì¤‘ìš”!)\n",
        "        X.columns = X.columns.map(str)\n",
        "\n",
        "        # 2. ìƒ˜í”Œ ìˆ˜ ì œí•œ\n",
        "        if sample_size and len(X) > sample_size:\n",
        "            X, _, y, _ = train_test_split(X, y, train_size=sample_size, random_state=42)\n",
        "\n",
        "        # 3. ëª¨ë¸ í•™ìŠµ\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # 4. SHAP ë¶„ì„\n",
        "        explainer = shap.Explainer(model, X)\n",
        "        shap_values = explainer(X)\n",
        "\n",
        "        # 5. ì‹œê°í™”\n",
        "        shap.summary_plot(shap_values, X, plot_type=\"dot\")\n",
        "\n",
        "        # 6. í‰ê·  SHAPê°’ í…Œì´ë¸”\n",
        "        mean_shap = pd.DataFrame({\n",
        "            \"Factor\": X.columns,\n",
        "            \"Mean |SHAP|\": np.abs(shap_values.values).mean(axis=0)\n",
        "        }).sort_values(by=\"Mean |SHAP|\", ascending=False)\n",
        "\n",
        "        print(mean_shap.round(4))\n",
        "        return mean_shap\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ì˜¤ë¥˜] {target_asset}ì— ëŒ€í•œ SHAP ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n"
      ],
      "metadata": {
        "id": "XJ5NtBflqpbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_shap_beta_feature_importance(factors, returns, target_asset, sample_size=1000):\n",
        "    try:\n",
        "        # 1. factorì—ì„œ dropna\n",
        "        X = factors.dropna()\n",
        "\n",
        "        # 2. ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬ (íŠœí”Œ â†’ ë¬¸ìì—´)\n",
        "        X.columns = [\n",
        "            f\"{col[0]}_{col[1]}\" if isinstance(col, tuple) else str(col)\n",
        "            for col in X.columns\n",
        "        ]\n",
        "\n",
        "        # 3. beta ê´€ë ¨ factorë§Œ ì„ íƒ\n",
        "        beta_columns = [col for col in X.columns if 'beta' in col.lower()]\n",
        "        X = X[beta_columns]\n",
        "\n",
        "        # âœ… returnsì™€ì˜ ê³µí†µ ì¸ë±ìŠ¤ ì¶”ì¶œ\n",
        "        common_index = X.index.intersection(returns[target_asset].dropna().index)\n",
        "        X = X.loc[common_index]\n",
        "        y = returns[target_asset].loc[common_index]\n",
        "\n",
        "        # ğŸ” ëª¨ë“  ì»¬ëŸ¼ ì´ë¦„ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
        "        X.columns = X.columns.map(str)\n",
        "\n",
        "        # 2. ìƒ˜í”Œ ìˆ˜ ì œí•œ\n",
        "        if sample_size and len(X) > sample_size:\n",
        "            X, _, y, _ = train_test_split(X, y, train_size=sample_size, random_state=42)\n",
        "\n",
        "        # 3. ëª¨ë¸ í•™ìŠµ\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # 4. SHAP ë¶„ì„\n",
        "        explainer = shap.Explainer(model, X)\n",
        "        shap_values = explainer(X)\n",
        "\n",
        "        # 5. ì‹œê°í™”\n",
        "        shap.summary_plot(shap_values, X, plot_type=\"dot\")\n",
        "\n",
        "        # 6. í‰ê·  SHAPê°’ ì •ë¦¬\n",
        "        mean_shap = pd.DataFrame({\n",
        "            \"Factor\": X.columns,\n",
        "            \"Mean |SHAP|\": np.abs(shap_values.values).mean(axis=0)\n",
        "        }).sort_values(by=\"Mean |SHAP|\", ascending=False)\n",
        "\n",
        "        print(mean_shap.round(4))\n",
        "        return mean_shap\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ì˜¤ë¥˜] {target_asset}ì— ëŒ€í•œ SHAP(beta) ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n"
      ],
      "metadata": {
        "id": "2xe3Nzic5zxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price, returns, factors = fetch_data(mixed_assets)\n",
        "\n",
        "for asset in mixed_assets:\n",
        "    print(f\"\\n=== SHAP ë¶„ì„ ì‹œì‘: {asset} ===\")\n",
        "    run_shap_feature_importance(factors=factors, returns=returns, target_asset=asset, sample_size=500)\n"
      ],
      "metadata": {
        "id": "oV4p_tz3awrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ìì‚°ë³„ ì¢…ê°€ë¥¼ ê°€ì ¸ì™€ì„œ price_df ìƒì„±\n",
        "# ë°ì´í„° ë‹¤ìš´ë¡œë“œ (MultiIndex ì²˜ë¦¬)\n",
        "raw_data = yf.download(mixed_assets, start=start_date, end=end_date, group_by='ticker' , auto_adjust=False)\n",
        "price_df = raw_data.xs(\"Adj Close\", axis=1, level=1)\n",
        "price_df = price_df.dropna(how='all')\n",
        "\n",
        "# ìˆ˜ìµë¥  ê³„ì‚°\n",
        "returns_df = price_df.pct_change().dropna()\n",
        "\n",
        "# SHAP ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
        "shap_results_all = {}"
      ],
      "metadata": {
        "id": "A9hoy2jbiMfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â–¶ í‰ê·  ìˆ˜ìµë¥ ì´ ê°€ì¥ ë†’ì€ ëª¨ë¸ ì„ íƒ\n",
        "mean_returns = {k: v.mean() for k, v in results.items()}\n",
        "best_model_key = max(mean_returns, key=mean_returns.get)\n",
        "print(f\"\\nâœ… ìˆ˜ìµë¥ ì´ ê°€ì¥ ë†’ì€ ëª¨ë¸: {best_model_key}\")\n",
        "\n",
        "# â–¶ í•´ë‹¹ ëª¨ë¸ë§Œ SHAP ë¶„ì„ ìˆ˜í–‰\n",
        "shap_results_all = {}\n",
        "\n",
        "for asset in mixed_assets:\n",
        "    try:\n",
        "        print(f\"[SHAP ì‹¤í–‰] ëª¨ë¸={best_model_key}, ìì‚°={asset}\")\n",
        "        shap_df = run_shap_beta_feature_importance(\n",
        "            factors=factors,\n",
        "            returns=returns_df,  # ì¢…ëª©ë³„ ìˆ˜ìµë¥  DataFrame\n",
        "            target_asset=asset,\n",
        "            sample_size=500\n",
        "        )\n",
        "        shap_results_all[f\"{best_model_key}_{asset}\"] = shap_df\n",
        "    except Exception as e:\n",
        "        print(f\"[ì˜¤ë¥˜] {asset}ì— ëŒ€í•œ SHAP ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n"
      ],
      "metadata": {
        "id": "OG85RSQuiCZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ìì‚°ë³„ ì¢…ê°€ë¥¼ ê°€ì ¸ì™€ì„œ price_df ìƒì„±\n",
        "# ë°ì´í„° ë‹¤ìš´ë¡œë“œ (MultiIndex ì²˜ë¦¬)\n",
        "raw_data = yf.download(mixed_assets, start=\"2018-01-01\", end=\"2024-12-31\", group_by='ticker' , auto_adjust=False)\n",
        "price_df = raw_data.xs(\"Adj Close\", axis=1, level=1)\n",
        "price_df = price_df.dropna(how='all')\n",
        "\n",
        "# ìˆ˜ìµë¥  ê³„ì‚°\n",
        "returns_df = price_df.pct_change().dropna()\n",
        "\n",
        "# SHAP ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
        "shap_results_all = {}\n",
        "\n",
        "for model_key, portfolio_returns in results.items():\n",
        "    for asset in mixed_assets:\n",
        "        try:\n",
        "            print(f\"[asset=]{asset} [model_key=]{model_key}\")\n",
        "            shap_df = run_shap_beta_feature_importance(\n",
        "                factors=factors,\n",
        "                returns=returns_df,  # âœ… ë°˜ë“œì‹œ ì¢…ëª©ë³„ ìˆ˜ìµë¥  DataFrame\n",
        "                target_asset=asset,\n",
        "                sample_size=500\n",
        "            )\n",
        "            shap_results_all[f\"{model_key}_{asset}\"] = shap_df\n",
        "        except Exception as e:\n",
        "            print(f\"[ì˜¤ë¥˜] {asset}ì— ëŒ€í•œ SHAP ì‹¤í–‰ ì‹¤íŒ¨: {e}\")"
      ],
      "metadata": {
        "id": "N86nhvxyrQcy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}