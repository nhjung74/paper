{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhjung74/paper/blob/main/factor_rl_portfolio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjVbbjLLAF8r",
        "outputId": "829a6d98-8dc0-46dd-9d38-44148fdffbf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "colab......\n",
            "g_drive= True\n"
          ]
        }
      ],
      "source": [
        "# 딥러닝 처리 환경 requirements\n",
        "g_drive = False\n",
        "mac_gpu = False\n",
        "# colab\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "# print(IN_COLAB)\n",
        "\n",
        "if IN_COLAB:\n",
        "    print('colab......')\n",
        "    g_drive = True\n",
        "    # google drive setting\n",
        "    #from google.colab import drive\n",
        "    #drive.mount('/content/drive')\n",
        "    #import os\n",
        "    #try:\n",
        "    #    import transformers, emoji, soynlp, pytorch_lightning\n",
        "    #except:\n",
        "    #    ! pip install -U -q transformers emoji soynlp pytorch-lightning snoop wandb sklearn seaborn pandas numpy\n",
        "    # restart runtime\n",
        "    #os.kill(os.getpid(), 9)\n",
        "elif IN_COLAB==False:\n",
        "    print('not colab')\n",
        "    g_drive = False\n",
        "    #import os\n",
        "    #try:\n",
        "    #    import transformers, emoji, soynlp, pytorch_lightning\n",
        "    #except:\n",
        "    #    ! pip install -U -q transformers emoji soynlp pytorch-lightning snoop wandb sklearn seaborn pandas numpy\n",
        "    #    ! pip install -q torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "\n",
        "print('g_drive=',g_drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jt7QMSmQALOD",
        "outputId": "3578eb34-d144-4f61-fd71-d08785d635c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Linux'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import platform\n",
        "\n",
        "platform.system()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtSEJo3EANjC"
      },
      "outputs": [],
      "source": [
        "os_type = platform.system()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7esZJ8wAQFQ",
        "outputId": "18f532ce-79c6-402b-aac7-ac7805646a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mac_gpu= False\n"
          ]
        }
      ],
      "source": [
        "# Os 종류를 확인한다.\n",
        "if os_type == 'Darwin':\n",
        "    mac_gpu = True\n",
        "else:\n",
        "    mac_gpu = False\n",
        "print('mac_gpu=',mac_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzUTNK2sASRg",
        "outputId": "7ca41776-0c2d-4063-ad79-0cd2dbb1dd6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n"
          ]
        }
      ],
      "source": [
        "if g_drive == True:\n",
        "  !pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if g_drive == True:\n",
        "  !pip install PyPortfolioOpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59d66bcf-a214-4a70-b3a4-15e321306478",
        "id": "1QQuVHJ4YY94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPortfolioOpt\n",
            "  Downloading pyportfolioopt-1.5.6-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: cvxpy>=1.1.19 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (1.6.6)\n",
            "Collecting ecos<3.0.0,>=2.0.14 (from PyPortfolioOpt)\n",
            "  Downloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (2.2.2)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (5.24.1)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (1.15.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (24.2)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (1.0.4)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (0.11.1)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (3.2.7.post2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.11/dist-packages (from clarabel>=0.5.0->cvxpy>=1.1.19->PyPortfolioOpt) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (75.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->PyPortfolioOpt) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi->clarabel>=0.5.0->cvxpy>=1.1.19->PyPortfolioOpt) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (3.0.2)\n",
            "Downloading pyportfolioopt-1.5.6-py3-none-any.whl (62 kB)\n",
            "Downloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
            "Installing collected packages: ecos, PyPortfolioOpt\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [PyPortfolioOpt]\n",
            "\u001b[1A\u001b[2KSuccessfully installed PyPortfolioOpt-1.5.6 ecos-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if g_drive == True:\n",
        "  !pip install shimmy>=0.2.1"
      ],
      "metadata": {
        "id": "37UgNTd56-ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if g_drive == True:\n",
        "  !pip install stable-baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff37697-33f0-421c-e0f7-94c9a5ac5223",
        "id": "HfgOeFUJ6-ex"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [stable-baselines3]\n",
            "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zL0l1Rtz_3T"
      },
      "outputs": [],
      "source": [
        "# 필요한 패키지 불러오기\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 디렉토리 설정\n",
        "if g_drive==False:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    base_dir = '/content/gdrive/My Drive/Colab Notebooks/aSSIST/factor_Project'\n",
        "    data_dir = os.path.join(base_dir, 'data')\n",
        "\n",
        "    # 디렉토리 생성\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    # 경로 이동\n",
        "    os.chdir(data_dir)\n",
        "\n",
        "    # 모델 저장 디렉토리 설정\n",
        "    MODEL_DIR = data_dir  # 또는 MODEL_DIR = os.getcwd()\n",
        "\n",
        "    # 경로 확인\n",
        "    print(f\"현재 작업 경로: {os.getcwd()}\")\n",
        "    print(f\"모델 저장 경로: {MODEL_DIR}\")"
      ],
      "metadata": {
        "id": "ACI-jNmSi8KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3Crew5Zz39x"
      },
      "outputs": [],
      "source": [
        "start_date ='2006-12-01'\n",
        "end_date ='2023-08-18'\n",
        "start_date2 ='01/12/2006'\n",
        "end_date2 ='08/08/2023'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYBiTktKAtEo",
        "outputId": "ea345e8f-cc75-4d7d-a8ee-0e2e6480790f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'=0.2.1'   sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noPxJw4VArMg",
        "outputId": "9cb7cb4c-81ce-4da7-cf99-962e3ba67604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 첫 번째 실험 (PPO + Crypto + Sharpe 보상)"
      ],
      "metadata": {
        "id": "U8aw7Xfnb8UB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 6가지 실험을 한 번에 실행하고 결과를 비교\n",
        "\n",
        "Crypto_PPO_sharpe\n",
        "\n",
        "Crypto_PPO_beta\n",
        "\n",
        "Crypto_SAC_sharpe\n",
        "\n",
        "Crypto_SAC_beta\n",
        "\n",
        "Crypto_TD3_sharpe\n",
        "\n",
        "Crypto_TD3_beta"
      ],
      "metadata": {
        "id": "4eyFZFQdfqxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종소스 20250616"
      ],
      "metadata": {
        "id": "CwQdLK-LzBGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_columns(df):\n",
        "    \"\"\"\n",
        "    문자열 컬럼 중 튜플처럼 생긴 것은 실제 튜플로 변환한다.\n",
        "    예: \"'('AAPL', 'beta_mom')'\" → ('AAPL', 'beta_mom')\n",
        "    \"\"\"\n",
        "    new_columns = []\n",
        "    for col in df.columns:\n",
        "        if isinstance(col, tuple):\n",
        "            new_columns.append(col)\n",
        "        elif isinstance(col, str) and col.startswith(\"(\") and col.endswith(\")\"):\n",
        "            try:\n",
        "                eval_col = eval(col)\n",
        "                if isinstance(eval_col, tuple):\n",
        "                    new_columns.append(eval_col)\n",
        "                else:\n",
        "                    new_columns.append(col)\n",
        "            except:\n",
        "                new_columns.append(col)\n",
        "        else:\n",
        "            new_columns.append(col)\n",
        "    df.columns = pd.Index(new_columns)\n",
        "    return df\n",
        "\n",
        "def run_shap_feature_importance_with_summary_flat(\n",
        "    factors, returns, target_asset=\"AAPL\", sample_size=1000,\n",
        "    all_factors=[\"beta_mom\", \"beta_vol\", \"beta_ma\", \"beta_volz\", \"beta_sharpe\", \"beta_mdd\"]\n",
        "):\n",
        "    print(f\"\\n=== SHAP 분석 시작: {target_asset} ===\")\n",
        "    try:\n",
        "        # 컬럼 정규화\n",
        "        factors = normalize_columns(factors)\n",
        "\n",
        "        # ✅ 필요한 tuple 컬럼만 선택\n",
        "        target_cols = [col for col in factors.columns\n",
        "                       if isinstance(col, tuple) and col[0] == target_asset and col[1] in all_factors]\n",
        "\n",
        "        if not target_cols:\n",
        "            print(f\"[오류] {target_asset}에 대한 beta 계열 팩터가 없습니다.\")\n",
        "            return\n",
        "\n",
        "        X = factors[target_cols].copy()\n",
        "        X.columns = [col[1] for col in X.columns]  # SHAP에서 요구하는 컬럼 이름으로 변경\n",
        "        y = returns[target_asset].loc[X.index].copy()\n",
        "\n",
        "        # 결측치 제거\n",
        "        valid_idx = X.dropna(how='all').index.intersection(y.dropna().index)\n",
        "        X = X.loc[valid_idx]\n",
        "        y = y.loc[valid_idx]\n",
        "\n",
        "        if len(X) == 0:\n",
        "            print(f\"[오류] 유효한 샘플이 없습니다.\")\n",
        "            return\n",
        "\n",
        "        if len(X) > sample_size:\n",
        "            X, _, y, _ = train_test_split(X, y, train_size=sample_size, random_state=42)\n",
        "\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        model.fit(X, y)\n",
        "        explainer = shap.Explainer(model, X)\n",
        "        shap_values = explainer(X)\n",
        "\n",
        "        mean_shap_df = pd.DataFrame({\n",
        "            \"Factor\": X.columns,\n",
        "            \"Mean |SHAP|\": np.abs(shap_values.values).mean(axis=0)\n",
        "        })\n",
        "\n",
        "        # 누락된 팩터 보완\n",
        "        missing_factors = set(all_factors) - set(mean_shap_df[\"Factor\"].values)\n",
        "        if missing_factors:\n",
        "            missing_df = pd.DataFrame({\n",
        "                \"Factor\": list(missing_factors),\n",
        "                \"Mean |SHAP|\": [0.0] * len(missing_factors)\n",
        "            })\n",
        "            mean_shap_df = pd.concat([mean_shap_df, missing_df], ignore_index=True)\n",
        "\n",
        "        mean_shap_df = mean_shap_df.sort_values(by=\"Mean |SHAP|\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "        print(mean_shap_df.round(4))\n",
        "        shap.summary_plot(shap_values, X, plot_type=\"dot\", show=True)\n",
        "\n",
        "        return mean_shap_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[오류] {target_asset}에 대한 SHAP 실행 실패: {str(e)}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "pBc2O7sxID09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP 분석을 위한 함수 개선\n",
        "def run_shap_analysis_for_all_models(experiments, factors, returns, sample_size=500):\n",
        "    factors = factors.copy()\n",
        "    factors = normalize_columns(factors)  # 튜플 컬럼 처리\n",
        "\n",
        "    shap_results = {}\n",
        "\n",
        "    for group, assets, algo_name, algo_class, objective in experiments:\n",
        "        if algo_class is None:\n",
        "            continue\n",
        "\n",
        "        key = f\"{group}_{algo_name}_{objective}\"\n",
        "        print(f\"\\n▶ Running SHAP analysis for: {key}\")\n",
        "\n",
        "        for asset in assets:\n",
        "            try:\n",
        "                print(f\"\\nAnalyzing asset: {asset}\")\n",
        "                shap_importance = run_shap_feature_importance_with_summary_flat(\n",
        "                    factors, returns, target_asset=asset, sample_size=sample_size\n",
        "                )\n",
        "                if shap_importance is not None:\n",
        "                    shap_results[f\"{key}_{asset}\"] = shap_importance\n",
        "            except Exception as e:\n",
        "                print(f\"Error analyzing {asset} in {key}: {str(e)}\")\n",
        "\n",
        "    return shap_results\n",
        "\n",
        "\n",
        "# 예시: Mixed 자산군을 기준으로 SHAP 데이터 구성\n",
        "_, selected_assets, _, _, _ = experiments[0]  # \"Mixed\" 자산군 선택\n",
        "price, returns, factors = fetch_data(selected_assets)\n",
        "\n",
        "\n",
        "# SHAP 분석 실행 (모든 모델과 자산에 대해)\n",
        "shap_results_all = run_shap_analysis_for_all_models(experiments, factors, returns)\n",
        "\n",
        "def summarize_shap_results(shap_results):\n",
        "    summary = []\n",
        "\n",
        "    for model_asset, result_df in shap_results.items():\n",
        "        if result_df is None:\n",
        "            continue\n",
        "\n",
        "        parts = model_asset.split('_')\n",
        "        model_name = '_'.join(parts[:-1])\n",
        "        asset = parts[-1]\n",
        "\n",
        "        for _, row in result_df.iterrows():\n",
        "            summary.append({\n",
        "                'Model': model_name,\n",
        "                'Asset': asset,\n",
        "                'Factor': row['Factor'],\n",
        "                'Mean|SHAP|': row.get('Mean|SHAP|', row.get('Mean |SHAP|', 0))\n",
        "            })\n",
        "\n",
        "    summary_df = pd.DataFrame(summary)\n",
        "    return summary_df\n",
        "\n",
        "\n",
        "\n",
        "# SHAP 결과 요약 생성\n",
        "shap_summary = summarize_shap_results(shap_results_all)\n",
        "\n",
        "# 모델별로 평균 SHAP 중요도 계산\n",
        "model_factor_importance = shap_summary.groupby(['Model', 'Factor'])['Mean|SHAP|'].mean().unstack()\n",
        "\n",
        "# 상위 10개 팩터 시각화\n",
        "plt.figure(figsize=(15, 8))\n",
        "model_factor_importance.mean().sort_values(ascending=False).head(10).plot(\n",
        "    kind='barh', title='Top 10 Most Important Factors Across All Models'\n",
        ")\n",
        "plt.xlabel(\"Average Mean Absolute SHAP Value\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 모델별로 가장 중요한 팩터 시각화\n",
        "for model in model_factor_importance.index:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    model_factor_importance.loc[model].sort_values(ascending=False).head(10).plot(\n",
        "        kind='barh', title=f'Top 10 Factors for {model}'\n",
        "    )\n",
        "    plt.xlabel(\"Mean Absolute SHAP Value\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 자산별로 가장 중요한 팩터 시각화\n",
        "asset_factor_importance = shap_summary.groupby(['Asset', 'Factor'])['Mean|SHAP|'].mean().unstack()\n",
        "\n",
        "for asset in asset_factor_importance.index:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    asset_factor_importance.loc[asset].sort_values(ascending=False).head(10).plot(\n",
        "        kind='barh', title=f'Top 10 Factors for {asset}'\n",
        "    )\n",
        "    plt.xlabel(\"Mean Absolute SHAP Value\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Xp7NDNwUljsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import shap\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from gym import spaces\n",
        "from stable_baselines3 import PPO, SAC, TD3\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import torch\n",
        "import random\n",
        "from sklearn.linear_model import LinearRegression  # 추가\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from scipy.stats import ttest_ind, mannwhitneyu\n",
        "\n",
        "from pypfopt import expected_returns, risk_models\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Seed 설정\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "show_summary = True\n",
        "\n",
        "# 자산군 설정\n",
        "stock_assets = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\"]\n",
        "crypto_assets = [\"BTC-USD\", \"ETH-USD\", \"BNB-USD\", \"SOL-USD\"]\n",
        "mixed_assets = stock_assets + crypto_assets #[\"BTC-USD\", \"ETH-USD\", \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"BNB-USD\", \"SOL-USD\"]\n",
        "\n",
        "print(mixed_assets)\n",
        "\n",
        "def save_model(model, save_path=\"models\", filename=\"ppo_model.zip\"):\n",
        "    import os\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    model.save(os.path.join(save_path, filename))\n",
        "\n",
        "def load_model(model_class, env, save_path=\"models\", filename=\"ppo_model.zip\"):\n",
        "    from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "    return model_class.load(os.path.join(save_path, filename), env=env)\n",
        "\n",
        "\n",
        "def compare_strategies(series1, series2, label1=\"A\", label2=\"B\"):\n",
        "    \"\"\"\n",
        "    두 포트폴리오 가치 시계열에 대해 t-test와 Mann–Whitney U-test 수행\n",
        "    \"\"\"\n",
        "    returns1 = series1.pct_change().dropna()\n",
        "    returns2 = series2.pct_change().dropna()\n",
        "\n",
        "    # 길이 맞추기\n",
        "    min_len = min(len(returns1), len(returns2))\n",
        "    returns1 = returns1[-min_len:]\n",
        "    returns2 = returns2[-min_len:]\n",
        "\n",
        "    # 평균차이 검정 (t-test)\n",
        "    t_stat, t_p = ttest_ind(returns1, returns2, equal_var=False)\n",
        "\n",
        "    # 비모수 검정 (Mann–Whitney U-test)\n",
        "    u_stat, u_p = mannwhitneyu(returns1, returns2, alternative='two-sided')\n",
        "\n",
        "    print(f\"\\n🔎 [{label1} vs {label2}]\")\n",
        "    print(f\"▶ t-test p-value: {t_p:.4f} → {'유의미함' if t_p < 0.05 else '유의미하지 않음'}\")\n",
        "    print(f\"▶ Mann–Whitney U-test p-value: {u_p:.4f} → {'유의미함' if u_p < 0.05 else '유의미하지 않음'}\")\n",
        "\n",
        "    return {\n",
        "        \"t_p\": t_p,\n",
        "        \"u_p\": u_p\n",
        "    }\n",
        "\n",
        "\n",
        "# 시간가변 베타 계산 함수 (추가)\n",
        "def compute_rolling_beta(price_data: pd.DataFrame, volume_data: pd.DataFrame, window: int = 60) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    기술적 요인(Momentum, Volatility, MA Deviation, Volume Z-score, Sharpe, MDD)을 이용해\n",
        "    각 자산별 60일 롤링 회귀를 수행하고, 시간가변적 베타 계수를 계산합니다.\n",
        "    \"\"\"\n",
        "    log_return = np.log(price_data / price_data.shift(1))\n",
        "    momentum = price_data.pct_change(20)\n",
        "    volatility = log_return.rolling(20).std()\n",
        "    ma = price_data.rolling(20).mean()\n",
        "    ma_deviation = (price_data - ma) / ma\n",
        "    volume_z = (volume_data - volume_data.rolling(20).mean()) / volume_data.rolling(20).std()\n",
        "\n",
        "    beta_data = {}\n",
        "    for asset in price_data.columns:\n",
        "        asset_df = pd.DataFrame({\n",
        "            \"y\": log_return[asset],\n",
        "            \"momentum\": momentum[asset],\n",
        "            \"volatility\": volatility[asset],\n",
        "            \"ma_dev\": ma_deviation[asset],\n",
        "            \"volume_z\": volume_z[asset]\n",
        "        }).dropna()\n",
        "\n",
        "        betas = []\n",
        "        index_list = []\n",
        "        for i in range(window, len(asset_df)):\n",
        "            y = asset_df[\"y\"].iloc[i - window:i].values\n",
        "            X = asset_df[[\"momentum\", \"volatility\", \"ma_dev\", \"volume_z\"]].iloc[i - window:i].values\n",
        "            price_window = price_data[asset].iloc[i - window:i]\n",
        "            returns = price_window.pct_change().dropna()\n",
        "            if np.any(np.isnan(X)) or np.any(np.isnan(y)) or returns.empty:\n",
        "                betas.append([np.nan] * 6)\n",
        "                index_list.append(asset_df.index[i])\n",
        "                continue\n",
        "            reg = LinearRegression().fit(X, y)\n",
        "            sharpe = returns.mean() / (returns.std() + 1e-6)\n",
        "            cumulative = (1 + returns).cumprod()\n",
        "            peak = cumulative.cummax()\n",
        "            drawdown = (cumulative - peak) / peak\n",
        "            mdd = drawdown.min()\n",
        "            beta_mdd = 1 - abs(mdd)  # MDD는 작을수록 좋음\n",
        "            betas.append(list(reg.coef_) + [sharpe, beta_mdd])\n",
        "            index_list.append(asset_df.index[i])\n",
        "\n",
        "        beta_df = pd.DataFrame(betas, columns=[\"beta_mom\", \"beta_vol\", \"beta_ma\", \"beta_volz\", \"beta_sharpe\", \"beta_mdd\"], index=index_list)\n",
        "        beta_data[asset] = beta_df\n",
        "\n",
        "    beta_panel = pd.concat(beta_data, axis=1)\n",
        "    beta_panel.index.name = \"Date\"\n",
        "    return beta_panel\n",
        "\n",
        "# 데이터 수집 함수 (수정: 거래량 데이터 추가 및 베타 통합)\n",
        "def fetch_data(assets, start=\"2019-01-01\", end=\"2024-12-31\"):\n",
        "    # 전체 데이터 다운로드 (종가 + 거래량)\n",
        "    data = yf.download(assets, start=start, end=end, auto_adjust=True, progress=False, threads=False)\n",
        "    price = data[\"Close\"].ffill().bfill().dropna()\n",
        "    volume = data[\"Volume\"].ffill().bfill().dropna()\n",
        "\n",
        "    # 기존 팩터 계산\n",
        "    returns = price.pct_change().dropna()\n",
        "    momentum = price.pct_change(20).dropna()\n",
        "    volatility = returns.rolling(20).std().dropna()\n",
        "    factors = pd.concat([momentum.add_suffix(\"_mom\"), volatility.add_suffix(\"_vol\")], axis=1).dropna()\n",
        "\n",
        "    # 시간가변 베타 계산 (추가)\n",
        "    beta_df = compute_rolling_beta(price, volume)\n",
        "\n",
        "    # 팩터와 베타 통합\n",
        "    combined_factors = pd.concat([factors, beta_df], axis=1).dropna()\n",
        "\n",
        "    # 인덱스 정렬\n",
        "    idx = price.index.intersection(combined_factors.index).intersection(returns.index)\n",
        "\n",
        "    if show_summary:\n",
        "        df_price = None\n",
        "        df_returns = None\n",
        "        df_factors = None\n",
        "\n",
        "        # 기술통계 요약 출력\n",
        "        print(\"\\n[기술통계 요약: Price]\")\n",
        "        print(price.loc[idx].describe().T.round(4))\n",
        "        df_price = price.loc[idx].describe().T.round(4)\n",
        "        df_price.to_excel('df_price.xlsx')\n",
        "\n",
        "        print(\"\\n[기술통계 요약: Returns]\")\n",
        "        print(returns.loc[idx].describe().T.round(4))\n",
        "        df_returns = returns.loc[idx].describe().T.round(4)\n",
        "        df_returns.to_excel('df_returns.xlsx')\n",
        "\n",
        "        print(\"\\n[기술통계 요약: Factors (Momentum, Volatility, Beta 등)]\")\n",
        "        print(combined_factors.loc[idx].describe().T.round(4))\n",
        "        df_factors = combined_factors.loc[idx].describe().T.round(4)\n",
        "        df_factors.to_excel('df_factors.xlsx')\n",
        "\n",
        "\n",
        "    return price.loc[idx], returns.loc[idx], combined_factors.loc[idx]\n",
        "\n",
        "# 강화학습 환경 (보상 계산 로직 수정: 베타 팩터 활용)\n",
        "class PPOPortfolioEnv(gym.Env):\n",
        "    def __init__(self, returns, factors, price, objective=\"sharpe\"):\n",
        "        super().__init__()\n",
        "        self.returns = returns\n",
        "        self.factors = factors\n",
        "        self.price = price\n",
        "        self.assets = returns.columns.tolist()\n",
        "        self.n_assets = len(self.assets)\n",
        "        self.window = 20\n",
        "        self.current_step = self.window\n",
        "        self.cash = 1.0\n",
        "        self.asset_quantity = np.zeros(self.n_assets)\n",
        "        self.portfolio_value = [1.0]\n",
        "        self.portfolio_returns = []\n",
        "        self.objective = objective\n",
        "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
        "\n",
        "        # 상태 공간 크기 자동 조정 (베타 팩터 추가로 인해)\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf,\n",
        "            shape=(self.window, factors.shape[1]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = self.window\n",
        "        self.cash = 1.0\n",
        "        self.asset_quantity = np.zeros(self.n_assets)\n",
        "        self.portfolio_value = [1.0]\n",
        "        self.portfolio_returns = []\n",
        "        return self.factors.iloc[self.current_step - self.window:self.current_step].values\n",
        "\n",
        "    def step(self, action):\n",
        "        action = np.clip(action, 0, 1)\n",
        "        action = action / (np.sum(action) + 1e-8)  # 포트폴리오 가중치 정규화\n",
        "\n",
        "        # 현재 가격 및 포트폴리오 가치\n",
        "        price_today = self.price.iloc[self.current_step].values\n",
        "        total_value = self.cash + np.sum(self.asset_quantity * price_today)\n",
        "\n",
        "        # 목표 자산 가치 계산\n",
        "        desired_value = action * total_value\n",
        "        current_value = self.asset_quantity * price_today\n",
        "        trade_value = desired_value - current_value\n",
        "\n",
        "        # 거래 비용 (0.1% 수수료)\n",
        "        cost = np.sum(np.abs(trade_value)) * 0.001\n",
        "        net_trade_value = trade_value - np.sign(trade_value) * cost / self.n_assets\n",
        "\n",
        "        # 자산 및 현금 업데이트\n",
        "        self.asset_quantity += net_trade_value / price_today\n",
        "        self.cash = total_value - np.sum(self.asset_quantity * price_today) - cost\n",
        "\n",
        "        # 다음 스텝의 포트폴리오 가치 계산\n",
        "        price_next = self.price.iloc[self.current_step + 1].values\n",
        "        port_value_next = self.cash + np.sum(self.asset_quantity * price_next)\n",
        "        port_return = (port_value_next - total_value) / total_value\n",
        "\n",
        "        self.portfolio_returns.append(port_return)\n",
        "        self.portfolio_value.append(port_value_next)\n",
        "        self.current_step += 1\n",
        "\n",
        "        # 종료 조건 확인\n",
        "        done = self.current_step >= len(self.returns) - 2\n",
        "\n",
        "        # 관측값 업데이트\n",
        "        obs = self.factors.iloc[self.current_step - self.window:self.current_step].values\n",
        "\n",
        "        # 보상 계산 (베타 팩터 활용 방식 수정)\n",
        "        if self.objective == \"sharpe\":\n",
        "            if len(self.portfolio_returns) > 1:\n",
        "                returns_window = np.array(self.portfolio_returns[-20:])\n",
        "                reward = np.mean(returns_window) / (np.std(returns_window) + 1e-6)\n",
        "            else:\n",
        "                reward = 0\n",
        "        elif self.objective == \"beta\":\n",
        "            # 베타 팩터 선택 (4개 팩터 중 모멘텀 베타 사용)\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                # 각 자산별 beta_mom 값 선택\n",
        "                beta_mom = self.factors.iloc[self.current_step - 1].get((asset, 'beta_mom'), 0)\n",
        "                beta_scores.append(beta_mom)\n",
        "            reward = np.dot(action, np.array(beta_scores))\n",
        "\n",
        "        elif self.objective == \"multi_beta\":\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                beta_total = 0\n",
        "                for factor_name in [\"beta_mom\", \"beta_vol\", \"beta_ma\", \"beta_volz\", \"beta_sharpe\", \"beta_mdd\"]:\n",
        "                    beta_val = self.factors.iloc[self.current_step - 1].get((asset, factor_name), 0)\n",
        "                    beta_total += beta_val\n",
        "                beta_scores.append(beta_total / 6.0)  # 단순 평균\n",
        "            reward = np.dot(action, np.array(beta_scores))\n",
        "\n",
        "        elif self.objective == \"hybrid\":\n",
        "            if len(self.portfolio_returns) > 1:\n",
        "                returns_window = np.array(self.portfolio_returns[-20:])\n",
        "                sharpe = np.mean(returns_window) / (np.std(returns_window) + 1e-6)\n",
        "            else:\n",
        "                sharpe = 0\n",
        "\n",
        "            # 베타 팩터 선택 (4개 팩터 중 모멘텀 베타 사용)\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                beta_mom = self.factors.iloc[self.current_step - 1].get((asset, 'beta_mom'), 0)\n",
        "                beta_scores.append(beta_mom)\n",
        "            beta = np.dot(action, np.array(beta_scores))\n",
        "            reward = 0.5 * sharpe + 0.5 * beta\n",
        "\n",
        "        elif self.objective == \"multi_hybrid\":\n",
        "            if len(self.portfolio_returns) > 1:\n",
        "                returns_window = np.array(self.portfolio_returns[-20:])\n",
        "                sharpe = np.mean(returns_window) / (np.std(returns_window) + 1e-6)\n",
        "            else:\n",
        "                sharpe = 0\n",
        "\n",
        "            beta_scores = []\n",
        "            for asset in self.assets:\n",
        "                beta_total = 0\n",
        "                for factor_name in [\"beta_mom\", \"beta_vol\", \"beta_ma\", \"beta_volz\", \"beta_sharpe\", \"beta_mdd\"]:\n",
        "                    beta_val = self.factors.iloc[self.current_step - 1].get((asset, factor_name), 0)\n",
        "                    beta_total += beta_val\n",
        "                beta_scores.append(beta_total / 6.0)\n",
        "            beta = np.dot(action, np.array(beta_scores))\n",
        "            reward = 0.5 * sharpe + 0.5 * beta\n",
        "        else:\n",
        "            reward = port_return\n",
        "\n",
        "        return obs, reward, done, {\"portfolio_value\": port_value_next}\n",
        "\n",
        "def equal_weight_backtest(price, transaction_cost=0.001):\n",
        "    \"\"\"\n",
        "    매일 리밸런싱 + 수수료 반영 + 자산 보유량 기반 백테스트\n",
        "    \"\"\"\n",
        "    returns = price.pct_change().dropna()\n",
        "    n_assets = returns.shape[1]\n",
        "    weights = np.ones(n_assets) / n_assets\n",
        "    portfolio_values = []\n",
        "    asset_quantity = np.zeros(n_assets)\n",
        "    cash = 1.0  # 초기 자본\n",
        "\n",
        "    for t in range(1, len(returns)):\n",
        "        prices_today = price.iloc[t - 1].values\n",
        "        total_value = cash + np.sum(asset_quantity * prices_today)\n",
        "\n",
        "        desired_value = total_value * weights\n",
        "        current_value = asset_quantity * prices_today\n",
        "        trade_value = desired_value - current_value\n",
        "\n",
        "        turnover = np.sum(np.abs(trade_value))\n",
        "        cost = turnover * transaction_cost\n",
        "\n",
        "        # 거래 반영\n",
        "        net_trade_value = trade_value - np.sign(trade_value) * cost / n_assets\n",
        "        asset_quantity += net_trade_value / prices_today\n",
        "        cash = total_value - np.sum(asset_quantity * prices_today) - cost\n",
        "\n",
        "        # 하루 후 가치 계산\n",
        "        prices_next = price.iloc[t].values\n",
        "        portfolio_value = cash + np.sum(asset_quantity * prices_next)\n",
        "        portfolio_values.append(portfolio_value)\n",
        "\n",
        "    return pd.Series(portfolio_values, index=returns.index[1:])\n",
        "\n",
        "\n",
        "def mvp_daily_rebalancing(price, lookback=60, transaction_cost=0.001):\n",
        "    \"\"\"\n",
        "    MVP 전략 기반 일일 리밸런싱 백테스트 (정확한 리밸런싱 반영)\n",
        "    \"\"\"\n",
        "    returns = price.pct_change().dropna()\n",
        "    portfolio_values = []\n",
        "    asset_quantity = np.zeros(len(price.columns))\n",
        "    cash = 1.0\n",
        "\n",
        "    for t in range(lookback, len(price) - 1):\n",
        "        window_price = price.iloc[t - lookback:t]\n",
        "        price_today = price.iloc[t].values\n",
        "\n",
        "        try:\n",
        "            mu = expected_returns.mean_historical_return(window_price, frequency=252)\n",
        "            S = risk_models.sample_cov(window_price, frequency=252)\n",
        "            ef = EfficientFrontier(mu, S)\n",
        "            ef.min_volatility()\n",
        "            weights = ef.clean_weights()\n",
        "            w = np.array([weights.get(ticker, 0.0) for ticker in price.columns])\n",
        "        except:\n",
        "            w = np.ones(len(price.columns)) / len(price.columns)\n",
        "\n",
        "        total_value = cash + np.sum(asset_quantity * price_today)\n",
        "\n",
        "        desired_value = w * total_value\n",
        "        current_value = asset_quantity * price_today\n",
        "        trade_value = desired_value - current_value\n",
        "\n",
        "        # 수수료 계산 및 반영\n",
        "        turnover = np.sum(np.abs(trade_value))\n",
        "        cost = turnover * transaction_cost\n",
        "\n",
        "        asset_quantity += trade_value / price_today\n",
        "        cash = total_value - np.sum(asset_quantity * price_today) - cost\n",
        "\n",
        "        # 다음 날 포트폴리오 가치\n",
        "        price_next = price.iloc[t + 1].values\n",
        "        portfolio_value = cash + np.sum(asset_quantity * price_next)\n",
        "\n",
        "        portfolio_values.append(portfolio_value)\n",
        "\n",
        "    index = price.index[lookback + 1:]\n",
        "    return pd.Series(portfolio_values, index=index)\n",
        "\n",
        "\n",
        "\n",
        "# 훈련 및 평가 함수 (수정: 평가 환경 개선)\n",
        "def train_and_evaluate(assets, algo_class, objective=\"sharpe\"):\n",
        "    price, returns, factors = fetch_data(assets)\n",
        "\n",
        "\n",
        "    if algo_class is None:\n",
        "        if objective == \"equal_weights\":\n",
        "            return equal_weight_backtest(price[assets], transaction_cost=0.001)\n",
        "        elif objective == \"mvp\":\n",
        "            return mvp_daily_rebalancing(price[assets], lookback=60, transaction_cost=0.001)\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        env = DummyVecEnv([lambda: PPOPortfolioEnv(returns, factors, price, objective)])\n",
        "        model = algo_class(\"MlpPolicy\", env, verbose=0, seed=SEED)\n",
        "        model.learn(total_timesteps=50000)\n",
        "\n",
        "        # 모델 저장\n",
        "        #model_path = os.path.join(MODEL_DIR, f\"ppo_{algo_class}_{objective}_model.zip\")\n",
        "        #model.save(model_path)\n",
        "        #print(f\"[저장 완료] {model_path}\")\n",
        "\n",
        "\n",
        "        # 평가\n",
        "        env_eval = PPOPortfolioEnv(returns, factors, price, objective)\n",
        "        obs = env_eval.reset()\n",
        "        values = [env_eval.portfolio_value[0]]\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            action, _ = model.predict(obs)\n",
        "            obs, reward, done, info = env_eval.step(action)\n",
        "            values.append(info[\"portfolio_value\"])\n",
        "\n",
        "        index = price.index[env_eval.window:env_eval.window + len(values)]\n",
        "        return pd.Series(values, index=index)\n",
        "\n",
        "\n",
        "# 성과 지표 계산 (수정: 올바른 연간화 계산)\n",
        "# 성과 지표 계산\n",
        "def performance_metrics(series):\n",
        "    returns = series.pct_change().dropna()\n",
        "    cumulative_return = series.iloc[-1] / series.iloc[0] - 1\n",
        "    annualized_return = (series.iloc[-1] / series.iloc[0]) ** (252 / len(series)) - 1\n",
        "    cagr = annualized_return  # 중복 제거\n",
        "    annualized_vol = returns.std() * np.sqrt(252)\n",
        "    sharpe = (cagr - 0.0) / (annualized_vol + 1e-6)\n",
        "    downside_std = returns[returns < 0].std() * np.sqrt(252)\n",
        "    sortino = (cagr - 0.0) / (downside_std + 1e-6)\n",
        "    peak = series.cummax()\n",
        "    drawdown = (series - peak) / peak\n",
        "    mdd = drawdown.min()\n",
        "    mdd = drawdown.min()\n",
        "    if len(returns) == 0:\n",
        "        turnover = 0.0\n",
        "    else:\n",
        "        turnover = (np.abs(returns).sum()) / len(returns)\n",
        "\n",
        "    return {\n",
        "        \"Sharpe Ratio\": sharpe,\n",
        "        \"Sortino Ratio\": sortino,\n",
        "        \"Cumulative Return\": cumulative_return,\n",
        "        \"Annualized Return\": cagr,\n",
        "        \"Annualized Volatility\": annualized_vol,\n",
        "        \"CAGR\": cagr,\n",
        "        \"Maximum Drawdown\": mdd,\n",
        "        \"Turnover Ratio\": turnover\n",
        "    }\n",
        "\n",
        "# XAI (SHAP 해석) 함수 추가\n",
        "import shap\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "def run_shap_feature_importance_with_summary(factors, returns, target_asset=\"BTC-USD\", sample_size=500):\n",
        "    \"\"\"\n",
        "    SHAP 분석을 통해 각 팩터가 수익률에 미치는 영향을 시각화하고,\n",
        "    Mean |SHAP value| 기준으로 수치 요약 결과를 반환\n",
        "    \"\"\"\n",
        "    # 데이터 정리\n",
        "    y = returns[target_asset].dropna()\n",
        "    X = factors.loc[y.index].copy()\n",
        "    X = X.dropna()\n",
        "    y = y.loc[X.index]\n",
        "\n",
        "    # 샘플 수 제한\n",
        "    if sample_size is not None and len(X) > sample_size:\n",
        "        X, _, y, _ = train_test_split(X, y, train_size=sample_size, random_state=42)\n",
        "\n",
        "    # 모델 학습\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # SHAP 계산\n",
        "    explainer = shap.Explainer(model.predict, X)\n",
        "    shap_values = explainer(X)\n",
        "\n",
        "    # 시각화 (beeswarm 형식)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shap.summary_plot(shap_values, X, plot_type=\"dot\", show=True)\n",
        "\n",
        "    # 📊 평균 SHAP 값 계산 (논문용 해석)\n",
        "    mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
        "    shap_importance = pd.DataFrame({\n",
        "        \"Factor\": X.columns,\n",
        "        \"Mean|SHAP|\": mean_abs_shap\n",
        "    }).sort_values(by=\"Mean|SHAP|\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n[SHAP 팩터 중요도 요약 (Mean Absolute SHAP Values)]\")\n",
        "    print(shap_importance.to_string(index=False))\n",
        "\n",
        "    return shap_importance\n",
        "\n",
        "\n",
        "# 실험 구성\n",
        "experiments = [\n",
        "#    (\"Crypto\", crypto_assets, \"EqualWeight\", None, \"equal_weights\"),\n",
        "#    (\"Crypto\", crypto_assets, \"MeanVariance\", None, \"mvp\"),\n",
        "#    (\"Crypto\", crypto_assets, \"PPO\", PPO, \"sharpe\"),\n",
        "#    (\"Crypto\", crypto_assets, \"PPO\", PPO, \"beta\"),\n",
        "#    (\"Crypto\", crypto_assets, \"PPO\", PPO, \"multi_beta\"),\n",
        "#   (\"Crypto\", crypto_assets, \"PPO\", PPO, \"hybrid\"),\n",
        "#    (\"Crypto\", crypto_assets, \"PPO\", PPO, \"mulit_hybrid\"),\n",
        "##    (\"Crypto\", crypto_assets, \"SAC\", SAC, \"sharpe\"),\n",
        "#    (\"Crypto\", crypto_assets, \"SAC\", SAC, \"beta\"),\n",
        "#    (\"Crypto\", crypto_assets, \"SAC\", SAC, \"hybrid\"),\n",
        "#    (\"Crypto\", crypto_assets, \"TD3\", TD3, \"sharpe\"),\n",
        "#    (\"Crypto\", crypto_assets, \"TD3\", TD3, \"beta\"),\n",
        "#    (\"Crypto\", crypto_assets, \"TD3\", TD3, \"hybrid\"),\n",
        "#    (\"Crypto\", crypto_assets, \"TD3\", TD3, \"mulit_hybrid\"),\n",
        "\n",
        "#    (\"Stock\", stock_assets, \"PPO\", PPO, \"sharpe\"),\n",
        "#    (\"Stock\", stock_assets, \"PPO\", PPO, \"beta\"),\n",
        "#    (\"Stock\", stock_assets, \"PPO\", PPO, \"multi_beta\"),\n",
        "#    (\"Stock\", stock_assets, \"PPO\", PPO, \"hybrid\"),\n",
        "#    (\"Stock\", stock_assets, \"PPO\", PPO, \"multi_hybrid\"),\n",
        "#    (\"Stock\", stock_assets, \"SAC\", SAC, \"sharpe\"),\n",
        "#    (\"Stock\", stock_assets, \"SAC\", SAC, \"beta\"),\n",
        "#    (\"Stock\", stock_assets, \"SAC\", SAC, \"multi_beta\"),\n",
        "#    (\"Stock\", stock_assets, \"SAC\", SAC, \"hybrid\"),\n",
        "#    (\"Stock\", stock_assets, \"SAC\", SAC, \"multi_hybrid\"),\n",
        "                #    (\"Stock\", stock_assets, \"TD3\", TD3, \"sharpe\"),\n",
        "#    (\"Stock\", stock_assets, \"TD3\", TD3, \"beta\"),\n",
        "#    (\"Stock\", stock_assets, \"TD3\", TD3, \"hybrid\"),\n",
        "\n",
        "    (\"Mixed\", mixed_assets, \"EqualWeight\", None, \"equal_weights\"),\n",
        "    (\"Mixed\", mixed_assets, \"MeanVariance\", None, \"mvp\"),\n",
        "    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"sharpe\"),\n",
        "#    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"beta\"),\n",
        "    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"multi_beta\"),\n",
        "#    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"hybrid\"),\n",
        "    (\"Mixed\", mixed_assets, \"PPO\", PPO, \"multi_hybrid\"),\n",
        "\n",
        "\n",
        "    (\"Mixed\", mixed_assets, \"SAC\", SAC, \"sharpe\"),\n",
        "#    (\"Mixed\", mixed_assets, \"SAC\", SAC, \"beta\"),\n",
        "     (\"Mixed\", mixed_assets, \"SAC\", SAC, \"multi_beta\"),\n",
        "#    (\"Mixed\", mixed_assets, \"SAC\", SAC, \"hybrid\"),\n",
        "     (\"Mixed\", mixed_assets, \"SAC\", SAC, \"mulit_hybrid\"),\n",
        "    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"sharpe\"),\n",
        "#    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"beta\"),\n",
        "#    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"hybrid\"),\n",
        "    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"multi_beta\"),\n",
        "    (\"Mixed\", mixed_assets, \"TD3\", TD3, \"mulit_hybrid\"),\n",
        "]\n",
        "\n",
        "# 실험 실행\n",
        "results = {}\n",
        "previous_group = None\n",
        "\n",
        "for group, assets, algo_name, algo_class, objective in experiments:\n",
        "    key = f\"{group}_{algo_name}_{objective}\"\n",
        "    print(f\"▶ Running: {key}\")\n",
        "    try:\n",
        "        results[key] = train_and_evaluate(assets, algo_class, objective)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in {key}: {str(e)}\")\n",
        "        results[key] = None\n",
        "    # 그룹이 바뀔때만 기술통계 출력\n",
        "    if previous_group != group:\n",
        "        show_summary = True\n",
        "        previous_group = group\n",
        "    else:\n",
        "        show_summary = False\n",
        "\n",
        "\n",
        "# 성과 요약 (오류 제외)\n",
        "valid_results = {k: v for k, v in results.items() if v is not None}\n",
        "metrics_table = pd.DataFrame({k: performance_metrics(v) for k, v in valid_results.items()}).T\n",
        "print(metrics_table)\n",
        "\n",
        "# 성과 막대그래프\n",
        "metrics_table[[\"Cumulative Return\", \"Sharpe Ratio\", \"Maximum Drawdown\"]].plot(\n",
        "    kind=\"bar\", figsize=(12, 6), title=\"Asset Group Performance (by RL & Objective)\"\n",
        ")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 포트폴리오 가치 시계열 그래프\n",
        "results_df = pd.DataFrame(valid_results)\n",
        "results_df.plot(figsize=(12, 6), title=\"Portfolio Value Comparison\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# sharpe 를 baseline으로 하여 통계적으로 의미가 있는지 비교함\n",
        "summary = []\n",
        "\n",
        "for (group, assets, algo, model_cls, obj) in experiments:\n",
        "    if obj == \"sharpe\":\n",
        "        continue  # baseline 제외\n",
        "\n",
        "    base_key = f\"{group}_{algo}_sharpe\"\n",
        "    compare_key = f\"{group}_{algo}_{obj}\"\n",
        "\n",
        "    if base_key in results and compare_key in results:\n",
        "        res = compare_strategies(results[base_key], results[compare_key], label1=base_key, label2=compare_key)\n",
        "        summary.append({\n",
        "            \"Group\": group,\n",
        "            \"Algorithm\": algo,\n",
        "            \"CompareWith\": obj,\n",
        "            \"t_p\": res[\"t_p\"],\n",
        "            \"u_p\": res[\"u_p\"]\n",
        "        })\n",
        "\n",
        "summary_df = pd.DataFrame(summary)\n",
        "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"Comparison Results\", dataframe=summary_df)\n",
        "print(summary_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aPeFERh5SsNV",
        "outputId": "8789d817-0672-4ea8-d831-a6738925a9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'BTC-USD', 'ETH-USD', 'BNB-USD', 'SOL-USD']\n",
            "▶ Running: Mixed_EqualWeight_equal_weights\n",
            "\n",
            "[기술통계 요약: Price]\n",
            "          count        mean         std        min         25%         50%  \\\n",
            "Ticker                                                                       \n",
            "AAPL     1665.0    159.6826     35.3475    81.6295    133.6090    156.4945   \n",
            "AMZN     1665.0    150.5351     30.5135    81.8200    128.6340    156.4495   \n",
            "BNB-USD  1665.0    334.5481    182.3187    15.1853    239.7069    310.6347   \n",
            "BTC-USD  1665.0  38987.5909  20112.5706  9045.3906  22978.1172  36276.8047   \n",
            "ETH-USD  1665.0   2154.8572   1050.1261   222.9598   1552.0895   1961.2808   \n",
            "GOOGL    1665.0    123.3184     29.2873    67.7208    100.6330    122.9824   \n",
            "MSFT     1665.0    300.1123     75.1289   178.4626    239.2287    284.3375   \n",
            "SOL-USD  1665.0     70.9860     67.8793     0.5706     19.4937     36.1909   \n",
            "\n",
            "                75%          max  \n",
            "Ticker                            \n",
            "AAPL       180.1859     258.3967  \n",
            "AMZN       171.3900     232.9300  \n",
            "BNB-USD    485.9064     750.2726  \n",
            "BTC-USD  54529.1445  106140.6016  \n",
            "ETH-USD   2986.0132    4812.0874  \n",
            "GOOGL      141.3354     196.1963  \n",
            "MSFT       361.8228     464.0025  \n",
            "SOL-USD    133.9919     258.9343  \n",
            "\n",
            "[기술통계 요약: Returns]\n",
            "          count    mean     std     min     25%     50%     75%     max\n",
            "Ticker                                                                 \n",
            "AAPL     1665.0  0.0008  0.0149 -0.0801 -0.0035  0.0000  0.0062  0.1047\n",
            "AMZN     1665.0  0.0005  0.0185 -0.1405 -0.0056  0.0000  0.0066  0.1354\n",
            "BNB-USD  1665.0  0.0033  0.0465 -0.3327 -0.0153  0.0013  0.0199  0.6976\n",
            "BTC-USD  1665.0  0.0019  0.0318 -0.1597 -0.0130  0.0006  0.0161  0.1875\n",
            "ETH-USD  1665.0  0.0024  0.0415 -0.2720 -0.0172  0.0013  0.0219  0.2595\n",
            "GOOGL    1665.0  0.0007  0.0160 -0.0951 -0.0038  0.0000  0.0067  0.1022\n",
            "MSFT     1665.0  0.0006  0.0140 -0.0772 -0.0035  0.0000  0.0060  0.0823\n",
            "SOL-USD  1665.0  0.0057  0.0675 -0.4228 -0.0306  0.0003  0.0367  0.4728\n",
            "\n",
            "[기술통계 요약: Factors (Momentum, Volatility, Beta 등)]\n",
            "                         count    mean     std     min     25%     50%  \\\n",
            "AAPL_mom                1665.0  0.0161  0.0635 -0.1796 -0.0278  0.0175   \n",
            "AMZN_mom                1665.0  0.0103  0.0760 -0.3120 -0.0364  0.0154   \n",
            "BNB-USD_mom             1665.0  0.0802  0.3930 -0.6108 -0.0601  0.0165   \n",
            "BTC-USD_mom             1665.0  0.0407  0.1626 -0.4056 -0.0533  0.0173   \n",
            "ETH-USD_mom             1665.0  0.0524  0.2051 -0.4516 -0.0686  0.0156   \n",
            "...                        ...     ...     ...     ...     ...     ...   \n",
            "(SOL-USD, beta_vol)     1665.0  0.2021  1.0071 -5.7809 -0.2391  0.2278   \n",
            "(SOL-USD, beta_ma)      1665.0  0.2898  0.1207  0.0283  0.2029  0.2831   \n",
            "(SOL-USD, beta_volz)    1665.0  0.0041  0.0124 -0.0248 -0.0036  0.0015   \n",
            "(SOL-USD, beta_sharpe)  1665.0  0.0406  0.1413 -0.2710 -0.0326  0.0000   \n",
            "(SOL-USD, beta_mdd)     1665.0  0.7036  0.2092  0.2596  0.5589  0.6765   \n",
            "\n",
            "                           75%     max  \n",
            "AAPL_mom                0.0611  0.2440  \n",
            "AMZN_mom                0.0568  0.2611  \n",
            "BNB-USD_mom             0.1318  6.4291  \n",
            "BTC-USD_mom             0.1145  0.7157  \n",
            "ETH-USD_mom             0.1530  1.0699  \n",
            "...                        ...     ...  \n",
            "(SOL-USD, beta_vol)     0.6372  5.2914  \n",
            "(SOL-USD, beta_ma)      0.3620  0.8290  \n",
            "(SOL-USD, beta_volz)    0.0110  0.0431  \n",
            "(SOL-USD, beta_sharpe)  0.1144  0.4827  \n",
            "(SOL-USD, beta_mdd)     0.8390  1.0000  \n",
            "\n",
            "[64 rows x 8 columns]\n",
            "▶ Running: Mixed_MeanVariance_mvp\n",
            "\n",
            "[기술통계 요약: Price]\n",
            "          count        mean         std        min         25%         50%  \\\n",
            "Ticker                                                                       \n",
            "AAPL     1665.0    159.6826     35.3475    81.6295    133.6090    156.4945   \n",
            "AMZN     1665.0    150.5351     30.5135    81.8200    128.6340    156.4495   \n",
            "BNB-USD  1665.0    334.5481    182.3187    15.1853    239.7069    310.6347   \n",
            "BTC-USD  1665.0  38987.5909  20112.5706  9045.3906  22978.1172  36276.8047   \n",
            "ETH-USD  1665.0   2154.8572   1050.1261   222.9598   1552.0895   1961.2808   \n",
            "GOOGL    1665.0    123.3184     29.2873    67.7208    100.6330    122.9824   \n",
            "MSFT     1665.0    300.1123     75.1289   178.4626    239.2287    284.3375   \n",
            "SOL-USD  1665.0     70.9860     67.8793     0.5706     19.4937     36.1909   \n",
            "\n",
            "                75%          max  \n",
            "Ticker                            \n",
            "AAPL       180.1859     258.3967  \n",
            "AMZN       171.3900     232.9300  \n",
            "BNB-USD    485.9064     750.2726  \n",
            "BTC-USD  54529.1445  106140.6016  \n",
            "ETH-USD   2986.0132    4812.0874  \n",
            "GOOGL      141.3354     196.1963  \n",
            "MSFT       361.8228     464.0025  \n",
            "SOL-USD    133.9919     258.9343  \n",
            "\n",
            "[기술통계 요약: Returns]\n",
            "          count    mean     std     min     25%     50%     75%     max\n",
            "Ticker                                                                 \n",
            "AAPL     1665.0  0.0008  0.0149 -0.0801 -0.0035  0.0000  0.0062  0.1047\n",
            "AMZN     1665.0  0.0005  0.0185 -0.1405 -0.0056  0.0000  0.0066  0.1354\n",
            "BNB-USD  1665.0  0.0033  0.0465 -0.3327 -0.0153  0.0013  0.0199  0.6976\n",
            "BTC-USD  1665.0  0.0019  0.0318 -0.1597 -0.0130  0.0006  0.0161  0.1875\n",
            "ETH-USD  1665.0  0.0024  0.0415 -0.2720 -0.0172  0.0013  0.0219  0.2595\n",
            "GOOGL    1665.0  0.0007  0.0160 -0.0951 -0.0038  0.0000  0.0067  0.1022\n",
            "MSFT     1665.0  0.0006  0.0140 -0.0772 -0.0035  0.0000  0.0060  0.0823\n",
            "SOL-USD  1665.0  0.0057  0.0675 -0.4228 -0.0306  0.0003  0.0367  0.4728\n",
            "\n",
            "[기술통계 요약: Factors (Momentum, Volatility, Beta 등)]\n",
            "                         count    mean     std     min     25%     50%  \\\n",
            "AAPL_mom                1665.0  0.0161  0.0635 -0.1796 -0.0278  0.0175   \n",
            "AMZN_mom                1665.0  0.0103  0.0760 -0.3120 -0.0364  0.0154   \n",
            "BNB-USD_mom             1665.0  0.0802  0.3930 -0.6108 -0.0601  0.0165   \n",
            "BTC-USD_mom             1665.0  0.0407  0.1626 -0.4056 -0.0533  0.0173   \n",
            "ETH-USD_mom             1665.0  0.0524  0.2051 -0.4516 -0.0686  0.0156   \n",
            "...                        ...     ...     ...     ...     ...     ...   \n",
            "(SOL-USD, beta_vol)     1665.0  0.2021  1.0071 -5.7809 -0.2391  0.2278   \n",
            "(SOL-USD, beta_ma)      1665.0  0.2898  0.1207  0.0283  0.2029  0.2831   \n",
            "(SOL-USD, beta_volz)    1665.0  0.0041  0.0124 -0.0248 -0.0036  0.0015   \n",
            "(SOL-USD, beta_sharpe)  1665.0  0.0406  0.1413 -0.2710 -0.0326  0.0000   \n",
            "(SOL-USD, beta_mdd)     1665.0  0.7036  0.2092  0.2596  0.5589  0.6765   \n",
            "\n",
            "                           75%     max  \n",
            "AAPL_mom                0.0611  0.2440  \n",
            "AMZN_mom                0.0568  0.2611  \n",
            "BNB-USD_mom             0.1318  6.4291  \n",
            "BTC-USD_mom             0.1145  0.7157  \n",
            "ETH-USD_mom             0.1530  1.0699  \n",
            "...                        ...     ...  \n",
            "(SOL-USD, beta_vol)     0.6372  5.2914  \n",
            "(SOL-USD, beta_ma)      0.3620  0.8290  \n",
            "(SOL-USD, beta_volz)    0.0110  0.0431  \n",
            "(SOL-USD, beta_sharpe)  0.1144  0.4827  \n",
            "(SOL-USD, beta_mdd)     0.8390  1.0000  \n",
            "\n",
            "[64 rows x 8 columns]\n",
            "▶ Running: Mixed_TD3_sharpe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶ Running: Mixed_TD3_mulit_hybrid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 10.28GB > 10.24GB\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-3365942926.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"▶ Running: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error in {key}: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-16-3365942926.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(assets, algo_class, objective)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPPOPortfolioEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MlpPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;31m# 모델 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/td3/td3.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     ) -> SelfTD3:\n\u001b[0;32m--> 222\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/td3/td3.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_policy_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_noise_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_noise_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mnext_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Compute the next Q-values: min over all critics targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/td3/policies.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# assert deterministic, 'The TD3 actor only outputs deterministic actions'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPyTorchObs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_shap_feature_importance(factors, returns, target_asset=\"BTC-USD\", sample_size=1000):\n",
        "    try:\n",
        "        # 1. 대상 자산에 해당하는 팩터 컬럼 선택\n",
        "        if isinstance(factors.columns[0], tuple):\n",
        "            target_cols = [col for col in factors.columns if col[0] == target_asset]\n",
        "        else:\n",
        "            target_cols = [col for col in factors.columns if str(col).startswith(target_asset)]\n",
        "\n",
        "        if not target_cols:\n",
        "            print(f\"[Error] {target_asset} 관련 팩터 컬럼이 없습니다.\")\n",
        "            return\n",
        "\n",
        "        # 2. X, y 구성\n",
        "        X = factors[target_cols].dropna()\n",
        "        y = returns[target_asset].loc[X.index]\n",
        "\n",
        "        # 3. X 컬럼 이름을 문자열로 변환 (중요!!)\n",
        "        if isinstance(X.columns[0], tuple):\n",
        "            X.columns = ['_'.join(col) for col in X.columns]\n",
        "\n",
        "        # 4. 샘플 수 제한\n",
        "        if sample_size and len(X) > sample_size:\n",
        "            X, _, y, _ = train_test_split(X, y, train_size=sample_size, random_state=42)\n",
        "\n",
        "        # 5. 모델 학습\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # 6. SHAP 분석\n",
        "        explainer = shap.Explainer(model, X)\n",
        "        shap_values = explainer(X)\n",
        "\n",
        "        # 7. SHAP summary plot\n",
        "        shap.summary_plot(shap_values, X, plot_type=\"dot\")\n",
        "\n",
        "        # 8. 평균 SHAP 값 표 출력\n",
        "        mean_shap = pd.DataFrame({\n",
        "            \"Factor\": X.columns,\n",
        "            \"Mean |SHAP|\": np.abs(shap_values.values).mean(axis=0)\n",
        "        }).sort_values(by=\"Mean |SHAP|\", ascending=False)\n",
        "\n",
        "        print(mean_shap.round(4))\n",
        "        return mean_shap\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[오류] {target_asset}에 대한 SHAP 실행 실패: {e}\")\n"
      ],
      "metadata": {
        "id": "bmSfBaAuajJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for asset in mixed_assets:\n",
        "    print(f\"\\n=== SHAP 분석 시작: {asset} ===\")\n",
        "    run_shap_feature_importance(factors=factors, returns=returns, target_asset=asset, sample_size=500)\n"
      ],
      "metadata": {
        "id": "oV4p_tz3awrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mixed_assets = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"BTC-USD\", \"ETH-USD\", \"BNB-USD\", \"SOL-USD\"]\n",
        "mixed_assets = [\"AAPL\", \"MSFT\"]\n",
        "price, returns, factors = fetch_data(mixed_assets)\n",
        "\n",
        "for asset in mixed_assets:\n",
        "    run_shap_feature_importance_with_summary_flat(factors, returns, target_asset=asset)\n"
      ],
      "metadata": {
        "id": "gxtTsD4ZIEq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_output_as_target(model, env_class, env_kwargs, date_index):\n",
        "    \"\"\"\n",
        "    PPO 등 RL 모델에서 생성된 포트폴리오 수익률을 y 타깃으로 반환\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "    # 환경 생성\n",
        "    env = DummyVecEnv([lambda: env_class(**env_kwargs)])\n",
        "\n",
        "    # 환경 초기화\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    daily_returns = []\n",
        "\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "\n",
        "        # reward를 바로 사용해도 되지만, 포트폴리오 수익률을 얻고 싶으면 info 활용\n",
        "        if isinstance(info, list):\n",
        "            info = info[0]  # DummyVecEnv는 리스트 형태로 반환\n",
        "\n",
        "        daily_return = info.get(\"daily_return\", reward)\n",
        "        daily_returns.append(daily_return)\n",
        "\n",
        "    # SHAP 타깃 y로 반환 (DataFrame)\n",
        "    y = pd.Series(daily_returns, index=date_index[:len(daily_returns)], name=\"PortfolioReturn\")\n",
        "    return y\n",
        "\n",
        "def run_model_shap_analysis(factors, returns, price, reward_type, model_class, model_name):\n",
        "    print(f\"\\n=== SHAP 분석 시작: {model_name} with reward = {reward_type} ===\")\n",
        "\n",
        "    # 환경 생성 인자\n",
        "    env_kwargs = {\n",
        "        \"price\": price,\n",
        "        \"returns\": returns,\n",
        "        \"factors\": factors,\n",
        "    }\n",
        "\n",
        "    # 환경 생성\n",
        "    env = DummyVecEnv([lambda: PPOPortfolioEnv(**env_kwargs)])\n",
        "\n",
        "    # 모델 로드 (확장자 .zip 제거)\n",
        "    model_path = f\"{model_name.lower()}_{reward_type}_model\"\n",
        "    model = model_class.load(model_path)\n",
        "\n",
        "    # SHAP 타깃 생성\n",
        "    y = get_model_output_as_target(model, PPOPortfolioEnv, env_kwargs, date_index=returns.index)\n",
        "\n",
        "    # SHAP 실행\n",
        "    mixed_assets = price.columns.tolist()\n",
        "    for asset in mixed_assets:\n",
        "        run_shap_feature_importance_with_summary_flat(factors, y, target_asset=asset)\n"
      ],
      "metadata": {
        "id": "5vvZhRpTo40K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로딩\n",
        "price, returns, factors = fetch_data([\"AAPL\", \"MSFT\"])\n",
        "\n",
        "# 분석 수행\n",
        "for reward_type in [\"sharpe\", \"multi_beta\", \"multi_hybrid\"]:\n",
        "    run_model_shap_analysis(factors, returns, price, reward_type, PPO, model_name=\"PPO\")\n"
      ],
      "metadata": {
        "id": "vErXpNT-s3X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for reward_type in [\"sharpe\", \"multi_beta\", \"multi_hybrid\"]:\n",
        "    run_model_shap_analysis(factors, returns, reward_type=reward_type)"
      ],
      "metadata": {
        "id": "bU0P-bYurDuT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}